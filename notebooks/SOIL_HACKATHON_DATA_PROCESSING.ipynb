{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **SOIL Hackathon -> üìä Data Preprocessing**\n",
        "\n",
        "- **Team: DATAGEEKS**\n",
        "- **Date: January 2026**"
      ],
      "metadata": {
        "id": "PBD7GbMoJ2UB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **NOTEBOOK OVERVIEW**\n",
        "<HR>\n",
        "\n",
        "This notebook contains the complete preprocessing pipeline for the ML Hackathon dual-task challenge:\n",
        "- Task 1: HDI Index Prediction (Regression)\n",
        "- Task 2: Happiness Index Classification\n",
        "\n",
        "Objective: Build ML models that minimize prediction errors across both tasks."
      ],
      "metadata": {
        "id": "X09RfTvYKjTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The raw dataset was **not directly usable** for either regression or classification due to:\n",
        "- Mixed and incorrect data types\n",
        "- Large variation in feature scales\n",
        "- Presence of extreme but valid outliers\n",
        "- Missing values in key indicators\n",
        "- Ordinal categorical variables stored as strings\n",
        "- Strong multicollinearity across socio‚Äëeconomic indicators\n",
        "\n",
        "<br>\n",
        "\n",
        "**CORE GOALS:**\n",
        "- Resolve data quality issues systematically\n",
        "- Create statistically learnable features\n",
        "- Ensure train/test consistency (no data leakage)\n",
        "- Reduce model error through intelligent transformations\n",
        "- Build a SINGLE unified pipeline for dual-task compatibility"
      ],
      "metadata": {
        "id": "Ifbj7REsLQAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PREPROCESSING SUMMARY**\n",
        "<hr>\n",
        "Concise summary of all transformations applied\n",
        "\n",
        "1. DATA TYPE CORRECTION\n",
        "   - Converted mis-typed object columns to numeric\n",
        "   - Retained true categorical features\n",
        "\n",
        "2. BINARY ENCODING\n",
        "   - Nuclear Power Status: Yes / No ‚Üí 1 / 0\n",
        "\n",
        "3. ORDINAL ENCODING\n",
        "   - Regulation Strictness ‚Üí 1 < 2 < 3 < 4\n",
        "   - Happiness Index ‚Üí 1 < 2 < 3 < 4\n",
        "   - Space Tech Level ‚Üí 1 < 2 < 3 < 4\n",
        "\n",
        "4. SCALE STANDARDIZATION\n",
        "   - Unified percentage features to 0‚Äì100 range\n",
        "   - Resolved decimal vs percentage inconsistency\n",
        "\n",
        "5. OUTLIER TREATMENT\n",
        "   - IQR-based capping on skewed numeric features\n",
        "   - No rows dropped\n",
        "\n",
        "6. BOUND ENFORCEMENT\n",
        "   - Enforced 0‚Äì100 limits on percentage columns\n",
        "   - Applied non-negative constraints on indices\n",
        "\n",
        "7. MISSING VALUE IMPUTATION\n",
        "   - Continuous ‚Üí Median\n",
        "   - Ordinal / Binary ‚Üí Mode\n",
        "   - Nominal ‚Üí 'Unknown'\n",
        "\n",
        "8. LOG TRANSFORMATION\n",
        "   - Applied to skewed features:\n",
        "     Population, GDP_per_Capita_USD,\n",
        "     Olympic_Medals_Count, Carbon_Footprint\n",
        "\n",
        "9. ONE-HOT ENCODING\n",
        "   - Nominal categories encoded with drop_first = True\n",
        "\n",
        "10. FEATURE CLEANUP\n",
        "    - Removed non-predictive identifiers (Country_Name)\n",
        "\n",
        "RESULT:\n",
        "Dataset is clean, consistent, and model-ready\n"
      ],
      "metadata": {
        "id": "8jUKvm_fNA09"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1: DataSet Loading & Initial Exploration"
      ],
      "metadata": {
        "id": "efQDJCDWNkMz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxWYWbaFJx7X"
      },
      "outputs": [],
      "source": [
        "# Import Required Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"LOADING DATASET\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_excel(\"/content/Round 1 - Dataset - SOIL Hackathon 2025 V1.0 (2).xlsx\")\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset loaded successfully!\")\n",
        "print(f\"   Rows: {df.shape[0]:,}\")\n",
        "print(f\"   Columns: {df.shape[1]:,}\")\n",
        "print(f\"   Total Data Points: {df.shape[0] * df.shape[1]:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJOAuSN0NuW8",
        "outputId": "39e75ff9-88f5-4e21-9ae3-4c4f67984ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "LOADING DATASET\n",
            "======================================================================\n",
            "\n",
            "‚úÖ Dataset loaded successfully!\n",
            "   Rows: 192\n",
            "   Columns: 33\n",
            "   Total Data Points: 6,336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Preview\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"DATASET PREVIEW - First 5 Rows\")\n",
        "print(\"=\" * 70)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "ZRCNktItNxnH",
        "outputId": "5ea2b33f-67f0-4848-9ed2-8872c5ea467e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "DATASET PREVIEW - First 5 Rows\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Country_Name Population GDP_per_Capita_USD  Literacy_Rate_pct  \\\n",
              "0  Afghanistan   99565202               2313           0.377674   \n",
              "1      Albania   59849246              23651           0.880994   \n",
              "2      Algeria   20094220              24706           0.809655   \n",
              "3      Andorra  175517703              17471          57.780239   \n",
              "4       Angola   77160475              10827           0.682256   \n",
              "\n",
              "   Internet_Access_pct  Gender_Equality_Index  Higher_Education_Rate  \\\n",
              "0             0.114579               0.277674                    NaN   \n",
              "1             0.735587               0.780994               0.535587   \n",
              "2             0.687641               0.709655               0.487641   \n",
              "3            37.333987              47.780239              17.333987   \n",
              "4             0.476237               0.582256               0.276237   \n",
              "\n",
              "   Govt_Education_Expenditure_pct_GDP  Life_Expectancy_years  \\\n",
              "0                                 NaN              57.231785   \n",
              "1                            0.061090              62.566575   \n",
              "2                            0.126652              76.289924   \n",
              "3                            0.000000              60.757345   \n",
              "4                            0.000000              63.096978   \n",
              "\n",
              "   Unemployment_Rate_pct  ...  Number_of_Religion Political_System_Type  \\\n",
              "0               0.242672  ...                   5             Autocracy   \n",
              "1               0.251704  ...                   6             Democracy   \n",
              "2               0.082113  ...                   4             Democracy   \n",
              "3              19.654495  ...                   5                Hybrid   \n",
              "4               0.307536  ...                   5                Hybrid   \n",
              "\n",
              "  Economic_Classification  Defence_expenditure_on_GDP Space_Tech_Level  \\\n",
              "0          Underdeveloped                    0.113390         Beginner   \n",
              "1               Developed                    0.029253            Elite   \n",
              "2               Developed                    0.085458            Elite   \n",
              "3              Developing                    0.000000     Intermediate   \n",
              "4              Developing                    0.000000     Intermediate   \n",
              "\n",
              "   Nuclear_Power_Status  Regulation_Strictness  Olympic_Medals_Count  \\\n",
              "0                    No                    Low                     0   \n",
              "1                   Yes                   High                    96   \n",
              "2                   Yes              Very High                   105   \n",
              "3                    No                 Medium                    30   \n",
              "4                    No                 Medium                    27   \n",
              "\n",
              "   HDI_Index  Happiness_Index  \n",
              "0   0.304889          Unhappy  \n",
              "1   0.627113            Happy  \n",
              "2   0.587591       Very Happy  \n",
              "3   0.480459            Happy  \n",
              "4   0.532973            Happy  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71d1b85f-9ae8-4aca-9f6d-ad5f834a90ed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country_Name</th>\n",
              "      <th>Population</th>\n",
              "      <th>GDP_per_Capita_USD</th>\n",
              "      <th>Literacy_Rate_pct</th>\n",
              "      <th>Internet_Access_pct</th>\n",
              "      <th>Gender_Equality_Index</th>\n",
              "      <th>Higher_Education_Rate</th>\n",
              "      <th>Govt_Education_Expenditure_pct_GDP</th>\n",
              "      <th>Life_Expectancy_years</th>\n",
              "      <th>Unemployment_Rate_pct</th>\n",
              "      <th>...</th>\n",
              "      <th>Number_of_Religion</th>\n",
              "      <th>Political_System_Type</th>\n",
              "      <th>Economic_Classification</th>\n",
              "      <th>Defence_expenditure_on_GDP</th>\n",
              "      <th>Space_Tech_Level</th>\n",
              "      <th>Nuclear_Power_Status</th>\n",
              "      <th>Regulation_Strictness</th>\n",
              "      <th>Olympic_Medals_Count</th>\n",
              "      <th>HDI_Index</th>\n",
              "      <th>Happiness_Index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>99565202</td>\n",
              "      <td>2313</td>\n",
              "      <td>0.377674</td>\n",
              "      <td>0.114579</td>\n",
              "      <td>0.277674</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>57.231785</td>\n",
              "      <td>0.242672</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>Autocracy</td>\n",
              "      <td>Underdeveloped</td>\n",
              "      <td>0.113390</td>\n",
              "      <td>Beginner</td>\n",
              "      <td>No</td>\n",
              "      <td>Low</td>\n",
              "      <td>0</td>\n",
              "      <td>0.304889</td>\n",
              "      <td>Unhappy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Albania</td>\n",
              "      <td>59849246</td>\n",
              "      <td>23651</td>\n",
              "      <td>0.880994</td>\n",
              "      <td>0.735587</td>\n",
              "      <td>0.780994</td>\n",
              "      <td>0.535587</td>\n",
              "      <td>0.061090</td>\n",
              "      <td>62.566575</td>\n",
              "      <td>0.251704</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>Democracy</td>\n",
              "      <td>Developed</td>\n",
              "      <td>0.029253</td>\n",
              "      <td>Elite</td>\n",
              "      <td>Yes</td>\n",
              "      <td>High</td>\n",
              "      <td>96</td>\n",
              "      <td>0.627113</td>\n",
              "      <td>Happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Algeria</td>\n",
              "      <td>20094220</td>\n",
              "      <td>24706</td>\n",
              "      <td>0.809655</td>\n",
              "      <td>0.687641</td>\n",
              "      <td>0.709655</td>\n",
              "      <td>0.487641</td>\n",
              "      <td>0.126652</td>\n",
              "      <td>76.289924</td>\n",
              "      <td>0.082113</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>Democracy</td>\n",
              "      <td>Developed</td>\n",
              "      <td>0.085458</td>\n",
              "      <td>Elite</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Very High</td>\n",
              "      <td>105</td>\n",
              "      <td>0.587591</td>\n",
              "      <td>Very Happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Andorra</td>\n",
              "      <td>175517703</td>\n",
              "      <td>17471</td>\n",
              "      <td>57.780239</td>\n",
              "      <td>37.333987</td>\n",
              "      <td>47.780239</td>\n",
              "      <td>17.333987</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60.757345</td>\n",
              "      <td>19.654495</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>Hybrid</td>\n",
              "      <td>Developing</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Intermediate</td>\n",
              "      <td>No</td>\n",
              "      <td>Medium</td>\n",
              "      <td>30</td>\n",
              "      <td>0.480459</td>\n",
              "      <td>Happy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Angola</td>\n",
              "      <td>77160475</td>\n",
              "      <td>10827</td>\n",
              "      <td>0.682256</td>\n",
              "      <td>0.476237</td>\n",
              "      <td>0.582256</td>\n",
              "      <td>0.276237</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>63.096978</td>\n",
              "      <td>0.307536</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>Hybrid</td>\n",
              "      <td>Developing</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Intermediate</td>\n",
              "      <td>No</td>\n",
              "      <td>Medium</td>\n",
              "      <td>27</td>\n",
              "      <td>0.532973</td>\n",
              "      <td>Happy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71d1b85f-9ae8-4aca-9f6d-ad5f834a90ed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71d1b85f-9ae8-4aca-9f6d-ad5f834a90ed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71d1b85f-9ae8-4aca-9f6d-ad5f834a90ed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e4cbefcd-90ee-4f77-884d-314898b3fd43\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e4cbefcd-90ee-4f77-884d-314898b3fd43')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e4cbefcd-90ee-4f77-884d-314898b3fd43 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Dimensions Analysis\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"DATASET DIMENSIONS\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Number of Records (Countries): {df.shape[0]}\")\n",
        "print(f\"Number of Features: {df.shape[1]}\")\n",
        "print(f\"Total Data Points: {df.shape[0] * df.shape[1]:,}\")\n",
        "print(\"\\nüìä INTERPRETATION:\")\n",
        "print(\"   ‚Ä¢ Each row represents ONE COUNTRY\")\n",
        "print(\"   ‚Ä¢ Each column represents a socioeconomic/political/development indicator\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGvicT-pOBV9",
        "outputId": "8286f595-3e61-4afb-aafd-6d457875d664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "DATASET DIMENSIONS\n",
            "======================================================================\n",
            "Number of Records (Countries): 192\n",
            "Number of Features: 33\n",
            "Total Data Points: 6,336\n",
            "\n",
            "üìä INTERPRETATION:\n",
            "   ‚Ä¢ Each row represents ONE COUNTRY\n",
            "   ‚Ä¢ Each column represents a socioeconomic/political/development indicator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Structure & Types\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"DATASET STRUCTURE & DATA TYPES\")\n",
        "print(\"=\" * 70)\n",
        "df.info()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"DATA TYPE DISTRIBUTION\")\n",
        "print(\"=\" * 70)\n",
        "print(df.dtypes.value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3LiAvN6OEE_",
        "outputId": "bd303e52-f987-4bbb-d839-e45a20821170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "DATASET STRUCTURE & DATA TYPES\n",
            "======================================================================\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 192 entries, 0 to 191\n",
            "Data columns (total 33 columns):\n",
            " #   Column                              Non-Null Count  Dtype  \n",
            "---  ------                              --------------  -----  \n",
            " 0   Country_Name                        192 non-null    object \n",
            " 1   Population                          192 non-null    object \n",
            " 2   GDP_per_Capita_USD                  192 non-null    object \n",
            " 3   Literacy_Rate_pct                   192 non-null    float64\n",
            " 4   Internet_Access_pct                 180 non-null    float64\n",
            " 5   Gender_Equality_Index               192 non-null    float64\n",
            " 6   Higher_Education_Rate               178 non-null    float64\n",
            " 7   Govt_Education_Expenditure_pct_GDP  186 non-null    float64\n",
            " 8   Life_Expectancy_years               192 non-null    float64\n",
            " 9   Unemployment_Rate_pct               192 non-null    float64\n",
            " 10  Days_engaged_in_warfare_per_year    192 non-null    int64  \n",
            " 11  Carbon_Footprint                    191 non-null    object \n",
            " 12  Medical_Doctors_per_1000            176 non-null    object \n",
            " 13  R_and_D_Expenditure_pct_GDP         180 non-null    float64\n",
            " 14  Number_of_Patents                   192 non-null    object \n",
            " 15  Number_of_Startups                  192 non-null    int64  \n",
            " 16  Number_of_PhD_holders_per_million   192 non-null    int64  \n",
            " 17  Trade_Partners_Count                192 non-null    int64  \n",
            " 18  Import_Rank_Global                  192 non-null    int64  \n",
            " 19  Export_Rank_Global                  192 non-null    int64  \n",
            " 20  Migration_Rate                      176 non-null    float64\n",
            " 21  Immigration_Rate                    178 non-null    float64\n",
            " 22  Language_Diversity_Level            192 non-null    object \n",
            " 23  Number_of_Religion                  192 non-null    int64  \n",
            " 24  Political_System_Type               192 non-null    object \n",
            " 25  Economic_Classification             192 non-null    object \n",
            " 26  Defence_expenditure_on_GDP          192 non-null    float64\n",
            " 27  Space_Tech_Level                    192 non-null    object \n",
            " 28  Nuclear_Power_Status                192 non-null    object \n",
            " 29  Regulation_Strictness               192 non-null    object \n",
            " 30  Olympic_Medals_Count                192 non-null    int64  \n",
            " 31  HDI_Index                           192 non-null    float64\n",
            " 32  Happiness_Index                     192 non-null    object \n",
            "dtypes: float64(12), int64(8), object(13)\n",
            "memory usage: 49.6+ KB\n",
            "\n",
            "======================================================================\n",
            "DATA TYPE DISTRIBUTION\n",
            "======================================================================\n",
            "object     13\n",
            "float64    12\n",
            "int64       8\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INITIAL OBSERVATIONS:\n",
        "- ‚ùå Multiple numeric values stored as 'object' type\n",
        "- ‚ùå Ordinal categorical variables stored as strings\n",
        "- ‚ùå Mixed feature scales (population vs. percentages)\n",
        "- ‚ùå Potential missing values requiring treatment"
      ],
      "metadata": {
        "id": "uqHb8n-sOMjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical Summary\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"STATISTICAL SUMMARY - NUMERIC FEATURES\")\n",
        "print(\"=\" * 70)\n",
        "df.describe().T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "XMI0QNsCOG8I",
        "outputId": "2c9443a4-29cd-438f-84b1-c4a9d8ed09f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "STATISTICAL SUMMARY - NUMERIC FEATURES\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    count         mean          std  \\\n",
              "Literacy_Rate_pct                   192.0    12.982547    26.037193   \n",
              "Internet_Access_pct                 180.0     9.511971    19.574579   \n",
              "Gender_Equality_Index               192.0    10.976218    22.229993   \n",
              "Higher_Education_Rate               178.0     5.487629    12.588724   \n",
              "Govt_Education_Expenditure_pct_GDP  186.0     1.045710     2.872131   \n",
              "Life_Expectancy_years               192.0    65.357638     5.490702   \n",
              "Unemployment_Rate_pct               192.0     4.251422     9.629637   \n",
              "Days_engaged_in_warfare_per_year    192.0    19.739583     9.224080   \n",
              "R_and_D_Expenditure_pct_GDP         180.0     0.774108     2.335388   \n",
              "Number_of_Startups                  192.0  9016.656250  7022.516430   \n",
              "Number_of_PhD_holders_per_million   192.0  1832.890625  1166.028124   \n",
              "Trade_Partners_Count                192.0    41.213542    21.834965   \n",
              "Import_Rank_Global                  192.0   115.473958    29.864780   \n",
              "Export_Rank_Global                  192.0   113.630208    35.223055   \n",
              "Migration_Rate                      176.0     1.701269     4.487117   \n",
              "Immigration_Rate                    178.0     1.958853     5.090083   \n",
              "Number_of_Religion                  192.0     5.088542     1.405849   \n",
              "Defence_expenditure_on_GDP          192.0     0.765354     2.226007   \n",
              "Olympic_Medals_Count                192.0    62.588542    41.887439   \n",
              "HDI_Index                           192.0     0.521207     0.125600   \n",
              "\n",
              "                                          min          25%          50%  \\\n",
              "Literacy_Rate_pct                    0.000000     0.502004     0.627940   \n",
              "Internet_Access_pct                  0.000000     0.299329     0.474204   \n",
              "Gender_Equality_Index                0.000000     0.402004     0.527940   \n",
              "Higher_Education_Rate                0.000000     0.098706     0.274204   \n",
              "Govt_Education_Expenditure_pct_GDP   0.000000     0.002189     0.042787   \n",
              "Life_Expectancy_years               50.000000    61.819780    65.466448   \n",
              "Unemployment_Rate_pct                0.000000     0.154988     0.231520   \n",
              "Days_engaged_in_warfare_per_year     0.000000    14.000000    19.000000   \n",
              "R_and_D_Expenditure_pct_GDP          0.000000     0.000000     0.022777   \n",
              "Number_of_Startups                   0.000000  3250.500000  8884.000000   \n",
              "Number_of_PhD_holders_per_million    0.000000   956.750000  1776.000000   \n",
              "Trade_Partners_Count                 1.000000    26.000000    43.000000   \n",
              "Import_Rank_Global                  30.000000    95.000000   116.000000   \n",
              "Export_Rank_Global                  13.000000    92.500000   113.500000   \n",
              "Migration_Rate                       0.000000     0.000000     0.063271   \n",
              "Immigration_Rate                     0.000000     0.000000     0.065242   \n",
              "Number_of_Religion                   3.000000     4.000000     5.000000   \n",
              "Defence_expenditure_on_GDP           0.000000     0.000000     0.032577   \n",
              "Olympic_Medals_Count                 0.000000    30.000000    63.500000   \n",
              "HDI_Index                            0.190053     0.432492     0.538262   \n",
              "\n",
              "                                             75%           max  \n",
              "Literacy_Rate_pct                       0.884633     93.660438  \n",
              "Internet_Access_pct                     0.761839     84.010823  \n",
              "Gender_Equality_Index                   0.784633     83.660438  \n",
              "Higher_Education_Rate                   0.561029     64.010823  \n",
              "Govt_Education_Expenditure_pct_GDP      0.093606     17.223471  \n",
              "Life_Expectancy_years                  68.710330     80.979236  \n",
              "Unemployment_Rate_pct                   0.373471     41.082778  \n",
              "Days_engaged_in_warfare_per_year       25.000000     50.000000  \n",
              "R_and_D_Expenditure_pct_GDP             0.064971     15.223471  \n",
              "Number_of_Startups                  12802.000000  32029.000000  \n",
              "Number_of_PhD_holders_per_million    2447.000000   5000.000000  \n",
              "Trade_Partners_Count                   53.000000    101.000000  \n",
              "Import_Rank_Global                    136.000000    200.000000  \n",
              "Export_Rank_Global                    137.000000    200.000000  \n",
              "Migration_Rate                          0.164346     30.163691  \n",
              "Immigration_Rate                        0.181702     31.617125  \n",
              "Number_of_Religion                      6.000000      9.000000  \n",
              "Defence_expenditure_on_GDP              0.084128     15.935493  \n",
              "Olympic_Medals_Count                   90.000000    200.000000  \n",
              "HDI_Index                               0.591930      0.850444  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c677f44e-d738-46e2-82b8-561a76e117fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Literacy_Rate_pct</th>\n",
              "      <td>192.0</td>\n",
              "      <td>12.982547</td>\n",
              "      <td>26.037193</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.502004</td>\n",
              "      <td>0.627940</td>\n",
              "      <td>0.884633</td>\n",
              "      <td>93.660438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Internet_Access_pct</th>\n",
              "      <td>180.0</td>\n",
              "      <td>9.511971</td>\n",
              "      <td>19.574579</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.299329</td>\n",
              "      <td>0.474204</td>\n",
              "      <td>0.761839</td>\n",
              "      <td>84.010823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gender_Equality_Index</th>\n",
              "      <td>192.0</td>\n",
              "      <td>10.976218</td>\n",
              "      <td>22.229993</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.402004</td>\n",
              "      <td>0.527940</td>\n",
              "      <td>0.784633</td>\n",
              "      <td>83.660438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Higher_Education_Rate</th>\n",
              "      <td>178.0</td>\n",
              "      <td>5.487629</td>\n",
              "      <td>12.588724</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.098706</td>\n",
              "      <td>0.274204</td>\n",
              "      <td>0.561029</td>\n",
              "      <td>64.010823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Govt_Education_Expenditure_pct_GDP</th>\n",
              "      <td>186.0</td>\n",
              "      <td>1.045710</td>\n",
              "      <td>2.872131</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002189</td>\n",
              "      <td>0.042787</td>\n",
              "      <td>0.093606</td>\n",
              "      <td>17.223471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Life_Expectancy_years</th>\n",
              "      <td>192.0</td>\n",
              "      <td>65.357638</td>\n",
              "      <td>5.490702</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>61.819780</td>\n",
              "      <td>65.466448</td>\n",
              "      <td>68.710330</td>\n",
              "      <td>80.979236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unemployment_Rate_pct</th>\n",
              "      <td>192.0</td>\n",
              "      <td>4.251422</td>\n",
              "      <td>9.629637</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.154988</td>\n",
              "      <td>0.231520</td>\n",
              "      <td>0.373471</td>\n",
              "      <td>41.082778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Days_engaged_in_warfare_per_year</th>\n",
              "      <td>192.0</td>\n",
              "      <td>19.739583</td>\n",
              "      <td>9.224080</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>50.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>R_and_D_Expenditure_pct_GDP</th>\n",
              "      <td>180.0</td>\n",
              "      <td>0.774108</td>\n",
              "      <td>2.335388</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022777</td>\n",
              "      <td>0.064971</td>\n",
              "      <td>15.223471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number_of_Startups</th>\n",
              "      <td>192.0</td>\n",
              "      <td>9016.656250</td>\n",
              "      <td>7022.516430</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3250.500000</td>\n",
              "      <td>8884.000000</td>\n",
              "      <td>12802.000000</td>\n",
              "      <td>32029.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number_of_PhD_holders_per_million</th>\n",
              "      <td>192.0</td>\n",
              "      <td>1832.890625</td>\n",
              "      <td>1166.028124</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>956.750000</td>\n",
              "      <td>1776.000000</td>\n",
              "      <td>2447.000000</td>\n",
              "      <td>5000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Trade_Partners_Count</th>\n",
              "      <td>192.0</td>\n",
              "      <td>41.213542</td>\n",
              "      <td>21.834965</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>101.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Import_Rank_Global</th>\n",
              "      <td>192.0</td>\n",
              "      <td>115.473958</td>\n",
              "      <td>29.864780</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>95.000000</td>\n",
              "      <td>116.000000</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>200.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Export_Rank_Global</th>\n",
              "      <td>192.0</td>\n",
              "      <td>113.630208</td>\n",
              "      <td>35.223055</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>92.500000</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>200.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Migration_Rate</th>\n",
              "      <td>176.0</td>\n",
              "      <td>1.701269</td>\n",
              "      <td>4.487117</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.063271</td>\n",
              "      <td>0.164346</td>\n",
              "      <td>30.163691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Immigration_Rate</th>\n",
              "      <td>178.0</td>\n",
              "      <td>1.958853</td>\n",
              "      <td>5.090083</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065242</td>\n",
              "      <td>0.181702</td>\n",
              "      <td>31.617125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Number_of_Religion</th>\n",
              "      <td>192.0</td>\n",
              "      <td>5.088542</td>\n",
              "      <td>1.405849</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>9.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Defence_expenditure_on_GDP</th>\n",
              "      <td>192.0</td>\n",
              "      <td>0.765354</td>\n",
              "      <td>2.226007</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.032577</td>\n",
              "      <td>0.084128</td>\n",
              "      <td>15.935493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Olympic_Medals_Count</th>\n",
              "      <td>192.0</td>\n",
              "      <td>62.588542</td>\n",
              "      <td>41.887439</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>63.500000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>200.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>HDI_Index</th>\n",
              "      <td>192.0</td>\n",
              "      <td>0.521207</td>\n",
              "      <td>0.125600</td>\n",
              "      <td>0.190053</td>\n",
              "      <td>0.432492</td>\n",
              "      <td>0.538262</td>\n",
              "      <td>0.591930</td>\n",
              "      <td>0.850444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c677f44e-d738-46e2-82b8-561a76e117fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c677f44e-d738-46e2-82b8-561a76e117fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c677f44e-d738-46e2-82b8-561a76e117fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9a0b6f05-4ba7-40cd-835d-3325c655280f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9a0b6f05-4ba7-40cd-835d-3325c655280f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9a0b6f05-4ba7-40cd-835d-3325c655280f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.061960773631965,\n        \"min\": 176.0,\n        \"max\": 192.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          180.0,\n          176.0,\n          178.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2029.8623667488775,\n        \"min\": 0.521206981181925,\n        \"max\": 9016.65625,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          12.982546950982039,\n          0.7653539739819237,\n          1.9588528491863124\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1574.7926146873472,\n        \"min\": 0.12559996144499583,\n        \"max\": 7022.5164301771,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          26.037193219738423,\n          2.2260072236357127,\n          5.090083365457759\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.78720741613495,\n        \"min\": 0.0,\n        \"max\": 50.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.0,\n          50.0,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"25%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 742.5826947696727,\n        \"min\": 0.0,\n        \"max\": 3250.5,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          0.5020038821643631,\n          0.2993289035676315,\n          61.81978035363815\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"50%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1999.591147130588,\n        \"min\": 0.022776773880158002,\n        \"max\": 8884.0,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.627939888327833,\n          0.0325770106201472,\n          0.06524221695924265\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"75%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2879.136376870175,\n        \"min\": 0.06497129171079954,\n        \"max\": 12802.0,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          0.8846333430103388,\n          0.08412796575526127,\n          0.18170209297693274\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7172.686728828287,\n        \"min\": 0.850444483536694,\n        \"max\": 32029.0,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          93.6604375142294,\n          84.0108231039336,\n          15.223471059854\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values Analysis\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"COMPREHENSIVE MISSING VALUES ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Calculate missing value statistics\n",
        "missing_data = pd.DataFrame({\n",
        "    'Column': df.columns,\n",
        "    'Missing_Count': df.isnull().sum().values,\n",
        "    'Missing_Percentage': (df.isnull().sum().values / len(df) * 100).round(2)\n",
        "})\n",
        "\n",
        "# Filter and sort by missing count\n",
        "missing_data = missing_data[missing_data['Missing_Count'] > 0].sort_values(\n",
        "    'Missing_Count', ascending=False\n",
        ")\n",
        "\n",
        "if len(missing_data) > 0:\n",
        "    print(missing_data.to_string(index=False))\n",
        "    print(f\"\\n‚ö†Ô∏è Total columns with missing values: {len(missing_data)}\")\n",
        "    print(f\"‚ö†Ô∏è Total missing data points: {missing_data['Missing_Count'].sum():,}\")\n",
        "    print(f\"‚ö†Ô∏è Overall missing percentage: {(missing_data['Missing_Count'].sum() / (df.shape[0] * df.shape[1]) * 100):.2f}%\")\n",
        "else:\n",
        "    print(\"‚úÖ No missing values detected in the dataset!\")\n",
        "\n",
        "# Visual representation of missing data\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"MISSING DATA PATTERN (Visual Representation)\")\n",
        "print(\"=\" * 70)\n",
        "for col in df.columns:\n",
        "    missing_pct = (df[col].isnull().sum() / len(df)) * 100\n",
        "    if missing_pct > 0:\n",
        "        bar_filled = int(missing_pct / 2)  # Scale to 50 chars max\n",
        "        bar = \"‚ñà\" * bar_filled + \"‚ñë\" * (50 - bar_filled)\n",
        "        print(f\"{col:35s} [{bar}] {missing_pct:.1f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO8fzC_kOeMf",
        "outputId": "b71edb5c-df0f-446e-e217-098567885f55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "COMPREHENSIVE MISSING VALUES ANALYSIS\n",
            "======================================================================\n",
            "                            Column  Missing_Count  Missing_Percentage\n",
            "                    Migration_Rate             16                8.33\n",
            "          Medical_Doctors_per_1000             16                8.33\n",
            "             Higher_Education_Rate             14                7.29\n",
            "                  Immigration_Rate             14                7.29\n",
            "               Internet_Access_pct             12                6.25\n",
            "       R_and_D_Expenditure_pct_GDP             12                6.25\n",
            "Govt_Education_Expenditure_pct_GDP              6                3.12\n",
            "                  Carbon_Footprint              1                0.52\n",
            "\n",
            "‚ö†Ô∏è Total columns with missing values: 8\n",
            "‚ö†Ô∏è Total missing data points: 91\n",
            "‚ö†Ô∏è Overall missing percentage: 1.44%\n",
            "\n",
            "======================================================================\n",
            "MISSING DATA PATTERN (Visual Representation)\n",
            "======================================================================\n",
            "Internet_Access_pct                 [‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 6.2%\n",
            "Higher_Education_Rate               [‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 7.3%\n",
            "Govt_Education_Expenditure_pct_GDP  [‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 3.1%\n",
            "Carbon_Footprint                    [‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 0.5%\n",
            "Medical_Doctors_per_1000            [‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 8.3%\n",
            "R_and_D_Expenditure_pct_GDP         [‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 6.2%\n",
            "Migration_Rate                      [‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 8.3%\n",
            "Immigration_Rate                    [‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë] 7.3%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Target Variables Distribution\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"TARGET VARIABLE ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# HDI Index (Regression Target)\n",
        "print(\"\\nüéØ HDI INDEX - REGRESSION TARGET\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"Data Type: {df['HDI_Index'].dtype}\")\n",
        "print(f\"Mean: {df['HDI_Index'].mean():.4f}\")\n",
        "print(f\"Std Dev: {df['HDI_Index'].std():.4f}\")\n",
        "print(f\"Min: {df['HDI_Index'].min():.4f}\")\n",
        "print(f\"Max: {df['HDI_Index'].max():.4f}\")\n",
        "print(f\"Range: {df['HDI_Index'].max() - df['HDI_Index'].min():.4f}\")\n",
        "print(f\"25th Percentile: {df['HDI_Index'].quantile(0.25):.4f}\")\n",
        "print(f\"Median: {df['HDI_Index'].median():.4f}\")\n",
        "print(f\"75th Percentile: {df['HDI_Index'].quantile(0.75):.4f}\")\n",
        "\n",
        "# Happiness Index (Classification Target)\n",
        "print(\"\\nüéØ HAPPINESS INDEX - CLASSIFICATION TARGET\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"Data Type: {df['Happiness_Index'].dtype}\")\n",
        "print(\"\\nClass Distribution (Counts):\")\n",
        "print(df['Happiness_Index'].value_counts().sort_index())\n",
        "print(\"\\nClass Distribution (Proportions):\")\n",
        "print(df['Happiness_Index'].value_counts(normalize=True).sort_index().round(3))\n",
        "\n",
        "# Check for class imbalance\n",
        "class_counts = df['Happiness_Index'].value_counts()\n",
        "max_class = class_counts.max()\n",
        "min_class = class_counts.min()\n",
        "imbalance_ratio = max_class / min_class\n",
        "print(f\"\\n‚ö†Ô∏è Class Imbalance Ratio: {imbalance_ratio:.2f}x\")\n",
        "if imbalance_ratio > 2:\n",
        "    print(\"   ‚Üí Moderate imbalance detected - may need handling in modeling phase\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoMKGWK_OhP0",
        "outputId": "9fffc488-6527-4bbe-bdbc-f3b75c806f27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "TARGET VARIABLE ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "üéØ HDI INDEX - REGRESSION TARGET\n",
            "----------------------------------------------------------------------\n",
            "Data Type: float64\n",
            "Mean: 0.5212\n",
            "Std Dev: 0.1256\n",
            "Min: 0.1901\n",
            "Max: 0.8504\n",
            "Range: 0.6604\n",
            "25th Percentile: 0.4325\n",
            "Median: 0.5383\n",
            "75th Percentile: 0.5919\n",
            "\n",
            "üéØ HAPPINESS INDEX - CLASSIFICATION TARGET\n",
            "----------------------------------------------------------------------\n",
            "Data Type: object\n",
            "\n",
            "Class Distribution (Counts):\n",
            "Happiness_Index\n",
            "Happy         105\n",
            "Unhappy        59\n",
            "Very Happy     28\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Class Distribution (Proportions):\n",
            "Happiness_Index\n",
            "Happy         0.547\n",
            "Unhappy       0.307\n",
            "Very Happy    0.146\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "‚ö†Ô∏è Class Imbalance Ratio: 3.75x\n",
            "   ‚Üí Moderate imbalance detected - may need handling in modeling phase\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 2: Comprehensive Data Quality Audit**\n",
        "\n",
        "**What we cover here:** Systematic identification of 5 critical data problems: incorrect data types, scale differences, skewed distributions, extreme outliers, and multicollinearity"
      ],
      "metadata": {
        "id": "h4t5cWZbXhAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 1 - Incorrect Data Types\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"DATA QUALITY AUDIT - PROBLEM IDENTIFICATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"‚ùå PROBLEM 1: INCORRECT DATA TYPES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "object_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "print(f\"\\nTotal columns stored as 'object' type: {len(object_cols)}\")\n",
        "print(\"\\nColumns requiring type conversion:\")\n",
        "\n",
        "for col in object_cols:\n",
        "    unique_count = df[col].nunique()\n",
        "    sample_values = df[col].dropna().unique()[:3]\n",
        "    print(f\"\\n  ‚Ä¢ {col}\")\n",
        "    print(f\"    Current Type: {df[col].dtype}\")\n",
        "    print(f\"    Unique Values: {unique_count}\")\n",
        "    print(f\"    Sample: {list(sample_values)}\")\n",
        "\n",
        "    # Identify what it should be\n",
        "    if col in ['Regulation_Strictness', 'Happiness_Index', 'Space_Tech_Level']:\n",
        "        print(f\"    ‚ö†Ô∏è Should be: Ordinal Numeric (contains hierarchy)\")\n",
        "    elif col == 'Nuclear_Power_Status':\n",
        "        print(f\"    ‚ö†Ô∏è Should be: Binary (0/1)\")\n",
        "    elif col in ['Political_System_Type', 'Economic_Classification', 'Language_Diversity_Level']:\n",
        "        print(f\"    ‚ö†Ô∏è Should be: Nominal Categorical (requires encoding)\")\n",
        "    elif col == 'Country_Name':\n",
        "        print(f\"    ‚ö†Ô∏è Should be: Identifier (drop before modeling)\")\n",
        "\n",
        "print(\"\\nüí° IMPACT ON MODELS:\")\n",
        "print(\"   ‚Üí ML algorithms cannot process text directly\")\n",
        "print(\"   ‚Üí Training will fail without proper conversion\")\n",
        "print(\"   ‚Üí Loss of ordinal relationships if not encoded properly\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-jsm1FSOlMa",
        "outputId": "f24af05f-ebe3-4098-90e5-1e20042a2ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "DATA QUALITY AUDIT - PROBLEM IDENTIFICATION\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "‚ùå PROBLEM 1: INCORRECT DATA TYPES\n",
            "================================================================================\n",
            "\n",
            "Total columns stored as 'object' type: 13\n",
            "\n",
            "Columns requiring type conversion:\n",
            "\n",
            "  ‚Ä¢ Country_Name\n",
            "    Current Type: object\n",
            "    Unique Values: 184\n",
            "    Sample: ['Afghanistan', 'Albania', 'Algeria']\n",
            "    ‚ö†Ô∏è Should be: Identifier (drop before modeling)\n",
            "\n",
            "  ‚Ä¢ Population\n",
            "    Current Type: object\n",
            "    Unique Values: 184\n",
            "    Sample: [99565202, 59849246, 20094220]\n",
            "\n",
            "  ‚Ä¢ GDP_per_Capita_USD\n",
            "    Current Type: object\n",
            "    Unique Values: 184\n",
            "    Sample: [2313, 23651, 24706]\n",
            "\n",
            "  ‚Ä¢ Carbon_Footprint\n",
            "    Current Type: object\n",
            "    Unique Values: 179\n",
            "    Sample: [4.1729272458256, 5.64973541826883, 5.22440510677186]\n",
            "\n",
            "  ‚Ä¢ Medical_Doctors_per_1000\n",
            "    Current Type: object\n",
            "    Unique Values: 167\n",
            "    Sample: [1.25279141712232, 2.28466779076466, 1.19048361115989]\n",
            "\n",
            "  ‚Ä¢ Number_of_Patents\n",
            "    Current Type: object\n",
            "    Unique Values: 169\n",
            "    Sample: [2895, 23859, 22226]\n",
            "\n",
            "  ‚Ä¢ Language_Diversity_Level\n",
            "    Current Type: object\n",
            "    Unique Values: 8\n",
            "    Sample: ['Low;Medium', 'High', 'Medium']\n",
            "    ‚ö†Ô∏è Should be: Nominal Categorical (requires encoding)\n",
            "\n",
            "  ‚Ä¢ Political_System_Type\n",
            "    Current Type: object\n",
            "    Unique Values: 6\n",
            "    Sample: ['Autocracy', 'Democracy', 'Hybrid']\n",
            "    ‚ö†Ô∏è Should be: Nominal Categorical (requires encoding)\n",
            "\n",
            "  ‚Ä¢ Economic_Classification\n",
            "    Current Type: object\n",
            "    Unique Values: 3\n",
            "    Sample: ['Underdeveloped', 'Developed', 'Developing']\n",
            "    ‚ö†Ô∏è Should be: Nominal Categorical (requires encoding)\n",
            "\n",
            "  ‚Ä¢ Space_Tech_Level\n",
            "    Current Type: object\n",
            "    Unique Values: 4\n",
            "    Sample: ['Beginner', 'Elite', 'Intermediate']\n",
            "    ‚ö†Ô∏è Should be: Ordinal Numeric (contains hierarchy)\n",
            "\n",
            "  ‚Ä¢ Nuclear_Power_Status\n",
            "    Current Type: object\n",
            "    Unique Values: 2\n",
            "    Sample: ['No', 'Yes']\n",
            "    ‚ö†Ô∏è Should be: Binary (0/1)\n",
            "\n",
            "  ‚Ä¢ Regulation_Strictness\n",
            "    Current Type: object\n",
            "    Unique Values: 5\n",
            "    Sample: ['Low', 'High', 'Very High']\n",
            "    ‚ö†Ô∏è Should be: Ordinal Numeric (contains hierarchy)\n",
            "\n",
            "  ‚Ä¢ Happiness_Index\n",
            "    Current Type: object\n",
            "    Unique Values: 3\n",
            "    Sample: ['Unhappy', 'Happy', 'Very Happy']\n",
            "    ‚ö†Ô∏è Should be: Ordinal Numeric (contains hierarchy)\n",
            "\n",
            "üí° IMPACT ON MODELS:\n",
            "   ‚Üí ML algorithms cannot process text directly\n",
            "   ‚Üí Training will fail without proper conversion\n",
            "   ‚Üí Loss of ordinal relationships if not encoded properly\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 2 - Skewed Distributions\n",
        "\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "scale_examples = ['Population', 'GDP_per_Capita_USD', 'HDI_Index', 'Literacy_Rate_pct']\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"‚ùå PROBLEM 3: HEAVILY SKEWED DISTRIBUTIONS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nSkewness Analysis (|skew| > 1 indicates strong skewness):\")\n",
        "print(f\"\\n{'Feature':<35} {'Skewness':>15} {'Interpretation':>20}\")\n",
        "print(\"-\" * 75)\n",
        "\n",
        "skewed_features = []\n",
        "for col in numeric_cols:\n",
        "    if df[col].notna().sum() > 0:\n",
        "        skewness = df[col].skew()\n",
        "        if abs(skewness) > 1:\n",
        "            skewed_features.append((col, skewness))\n",
        "\n",
        "skewed_features.sort(key=lambda x: abs(x[1]), reverse=True)\n",
        "\n",
        "for col, skew in skewed_features[:10]:\n",
        "    interpretation = \"Right-skewed\" if skew > 0 else \"Left-skewed\"\n",
        "    severity = \"Severe\" if abs(skew) > 2 else \"Moderate\"\n",
        "    print(f\"{col:<35} {skew:>15.2f} {interpretation:>15} ({severity})\")\n",
        "\n",
        "print(f\"\\nüí° Total features with |skew| > 1: {len(skewed_features)}\")\n",
        "print(\"\\nüí° IMPACT ON MODELS:\")\n",
        "print(\"   ‚Üí Reduces linear separability\")\n",
        "print(\"   ‚Üí Outliers dominate mean calculations\")\n",
        "print(\"   ‚Üí Poor gradient flow in neural networks\")\n",
        "print(\"   ‚Üí Violates normality assumptions in linear regression\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlAXxIWgYAhR",
        "outputId": "b5804464-0514-4764-f264-5f04f35c07f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "‚ùå PROBLEM 3: HEAVILY SKEWED DISTRIBUTIONS\n",
            "================================================================================\n",
            "\n",
            "Skewness Analysis (|skew| > 1 indicates strong skewness):\n",
            "\n",
            "Feature                                    Skewness       Interpretation\n",
            "---------------------------------------------------------------------------\n",
            "R_and_D_Expenditure_pct_GDP                    3.81    Right-skewed (Severe)\n",
            "Defence_expenditure_on_GDP                     3.66    Right-skewed (Severe)\n",
            "Govt_Education_Expenditure_pct_GDP             3.29    Right-skewed (Severe)\n",
            "Migration_Rate                                 3.27    Right-skewed (Severe)\n",
            "Immigration_Rate                               3.07    Right-skewed (Severe)\n",
            "Higher_Education_Rate                          2.67    Right-skewed (Severe)\n",
            "Unemployment_Rate_pct                          2.34    Right-skewed (Severe)\n",
            "Internet_Access_pct                            2.03    Right-skewed (Severe)\n",
            "Gender_Equality_Index                          1.83    Right-skewed (Moderate)\n",
            "Literacy_Rate_pct                              1.76    Right-skewed (Moderate)\n",
            "\n",
            "üí° Total features with |skew| > 1: 10\n",
            "\n",
            "üí° IMPACT ON MODELS:\n",
            "   ‚Üí Reduces linear separability\n",
            "   ‚Üí Outliers dominate mean calculations\n",
            "   ‚Üí Poor gradient flow in neural networks\n",
            "   ‚Üí Violates normality assumptions in linear regression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 3 - Extreme Outliers\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"‚ùå PROBLEM 4: EXTREME OUTLIERS (IQR Method)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nOutlier Detection (values beyond Q3 + 1.5*IQR):\")\n",
        "print(f\"\\n{'Feature':<35} {'Outlier Count':>15} {'Outlier %':>15}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "outlier_features = []\n",
        "for col in numeric_cols[:15]:\n",
        "    if df[col].notna().sum() > 0:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        outliers = ((df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))).sum()\n",
        "        outlier_pct = (outliers / len(df)) * 100\n",
        "\n",
        "        if outliers > 0:\n",
        "            outlier_features.append((col, outliers, outlier_pct))\n",
        "\n",
        "outlier_features.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "for col, count, pct in outlier_features[:10]:\n",
        "    print(f\"{col:<35} {count:>15,} {pct:>14.1f}%\")\n",
        "\n",
        "print(f\"\\nüí° Total features with outliers: {len(outlier_features)}\")\n",
        "print(\"\\nüí° IMPACT ON MODELS:\")\n",
        "print(\"   ‚Üí Overfitting to extreme cases\")\n",
        "print(\"   ‚Üí Poor generalization to new data\")\n",
        "print(\"   ‚Üí Inflated error metrics (RMSE, MAE)\")\n",
        "print(\"   ‚Üí Unstable model parameters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5UCj2KjZCWu",
        "outputId": "fc615226-d0b0-4e16-ae87-8f0c272c9221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "‚ùå PROBLEM 4: EXTREME OUTLIERS (IQR Method)\n",
            "================================================================================\n",
            "\n",
            "Outlier Detection (values beyond Q3 + 1.5*IQR):\n",
            "\n",
            "Feature                               Outlier Count       Outlier %\n",
            "----------------------------------------------------------------------\n",
            "Literacy_Rate_pct                                37           19.3%\n",
            "Gender_Equality_Index                            37           19.3%\n",
            "Unemployment_Rate_pct                            37           19.3%\n",
            "Internet_Access_pct                              36           18.8%\n",
            "Higher_Education_Rate                            35           18.2%\n",
            "Migration_Rate                                   29           15.1%\n",
            "Govt_Education_Expenditure_pct_GDP               27           14.1%\n",
            "R_and_D_Expenditure_pct_GDP                      23           12.0%\n",
            "Number_of_Startups                                4            2.1%\n",
            "Number_of_PhD_holders_per_million                 4            2.1%\n",
            "\n",
            "üí° Total features with outliers: 15\n",
            "\n",
            "üí° IMPACT ON MODELS:\n",
            "   ‚Üí Overfitting to extreme cases\n",
            "   ‚Üí Poor generalization to new data\n",
            "   ‚Üí Inflated error metrics (RMSE, MAE)\n",
            "   ‚Üí Unstable model parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Problem 5 - Multicollinearity\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"‚ùå PROBLEM 5: MULTICOLLINEARITY BETWEEN FEATURES\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = df.select_dtypes(include=['int64', 'float64']).corr().abs()\n",
        "\n",
        "# Find highly correlated pairs\n",
        "high_corr_pairs = []\n",
        "for i in range(len(correlation_matrix.columns)):\n",
        "    for j in range(i+1, len(correlation_matrix.columns)):\n",
        "        corr_value = correlation_matrix.iloc[i, j]\n",
        "        if corr_value > 0.8:\n",
        "            high_corr_pairs.append((\n",
        "                correlation_matrix.columns[i],\n",
        "                correlation_matrix.columns[j],\n",
        "                corr_value\n",
        "            ))\n",
        "\n",
        "high_corr_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "print(f\"\\nHighly Correlated Feature Pairs (|r| > 0.8):\")\n",
        "print(f\"\\n{'Feature 1':<30} {'Feature 2':<30} {'Correlation':>15}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for col1, col2, corr in high_corr_pairs[:15]:\n",
        "    print(f\"{col1:<30} {col2:<30} {corr:>15.3f}\")\n",
        "\n",
        "print(f\"\\nüí° Total highly correlated pairs found: {len(high_corr_pairs)}\")\n",
        "print(\"\\nüí° IMPACT ON MODELS:\")\n",
        "print(\"   ‚Üí Inflated variance in regression coefficients\")\n",
        "print(\"   ‚Üí Unstable model parameters\")\n",
        "print(\"   ‚Üí Difficulty interpreting feature importance\")\n",
        "print(\"   ‚Üí Reduced model generalization\")\n",
        "print(\"   ‚Üí Numerical instability in matrix operations\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP9XbfPnZFpG",
        "outputId": "2d5239e5-c516-4c30-bfc0-afe0a1f4dbcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "‚ùå PROBLEM 5: MULTICOLLINEARITY BETWEEN FEATURES\n",
            "================================================================================\n",
            "\n",
            "Highly Correlated Feature Pairs (|r| > 0.8):\n",
            "\n",
            "Feature 1                      Feature 2                          Correlation\n",
            "--------------------------------------------------------------------------------\n",
            "Literacy_Rate_pct              Gender_Equality_Index                    0.999\n",
            "Migration_Rate                 Immigration_Rate                         0.997\n",
            "Internet_Access_pct            Gender_Equality_Index                    0.993\n",
            "Govt_Education_Expenditure_pct_GDP R_and_D_Expenditure_pct_GDP              0.988\n",
            "Literacy_Rate_pct              Internet_Access_pct                      0.988\n",
            "Govt_Education_Expenditure_pct_GDP Defence_expenditure_on_GDP               0.979\n",
            "Internet_Access_pct            Higher_Education_Rate                    0.975\n",
            "R_and_D_Expenditure_pct_GDP    Defence_expenditure_on_GDP               0.974\n",
            "Gender_Equality_Index          Higher_Education_Rate                    0.944\n",
            "Literacy_Rate_pct              Higher_Education_Rate                    0.931\n",
            "Unemployment_Rate_pct          Migration_Rate                           0.891\n",
            "Unemployment_Rate_pct          Immigration_Rate                         0.889\n",
            "Higher_Education_Rate          Immigration_Rate                         0.874\n",
            "Gender_Equality_Index          Immigration_Rate                         0.866\n",
            "Internet_Access_pct            Immigration_Rate                         0.864\n",
            "\n",
            "üí° Total highly correlated pairs found: 26\n",
            "\n",
            "üí° IMPACT ON MODELS:\n",
            "   ‚Üí Inflated variance in regression coefficients\n",
            "   ‚Üí Unstable model parameters\n",
            "   ‚Üí Difficulty interpreting feature importance\n",
            "   ‚Üí Reduced model generalization\n",
            "   ‚Üí Numerical instability in matrix operations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Quality Summary\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DATA QUALITY ISSUES - EXECUTIVE SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\n‚úó Incorrect Data Types: {len(object_cols)} columns need conversion\")\n",
        "print(f\"‚úó Scale Differences: Features span multiple orders of magnitude\")\n",
        "print(f\"‚úó Skewed Distributions: {len(skewed_features)} features with |skew| > 1\")\n",
        "print(f\"‚úó Outlier-Affected Features: {len(outlier_features)} features\")\n",
        "print(f\"‚úó High Multicollinearity: {len(high_corr_pairs)} correlated pairs (r > 0.8)\")\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è CRITICAL: These issues MUST be addressed before model training!\")\n",
        "print(\"   ‚Üí Failure to preprocess will result in:\")\n",
        "print(\"      ‚Ä¢ Training failures\")\n",
        "print(\"      ‚Ä¢ Poor model performance\")\n",
        "print(\"      ‚Ä¢ Unreliable predictions\")\n",
        "print(\"      ‚Ä¢ High error rates\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HmLV0jIZJPk",
        "outputId": "d9e4ead8-92e2-4867-cd5c-ef5c6ef33668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "DATA QUALITY ISSUES - EXECUTIVE SUMMARY\n",
            "================================================================================\n",
            "\n",
            "‚úó Incorrect Data Types: 13 columns need conversion\n",
            "‚úó Scale Differences: Features span multiple orders of magnitude\n",
            "‚úó Skewed Distributions: 10 features with |skew| > 1\n",
            "‚úó Outlier-Affected Features: 15 features\n",
            "‚úó High Multicollinearity: 26 correlated pairs (r > 0.8)\n",
            "\n",
            "‚ö†Ô∏è CRITICAL: These issues MUST be addressed before model training!\n",
            "   ‚Üí Failure to preprocess will result in:\n",
            "      ‚Ä¢ Training failures\n",
            "      ‚Ä¢ Poor model performance\n",
            "      ‚Ä¢ Unreliable predictions\n",
            "      ‚Ä¢ High error rates\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 3: PreProcessing Philosophy**\n",
        "\n",
        "**What we cover here:** Establishing guiding principles that inform every preprocessing decision\n",
        "\n",
        "1. üéØ PRESERVE REAL-WORLD MEANING\n",
        "   - ransformations must maintain domain interpretability\n",
        "   - Business relevance is not sacrificed for mathematical convenience\n",
        "\n",
        "2. üîí PREVENT DATA LEAKAGE\n",
        "   - Strict separation between training and validation statistics\n",
        "   - No future information allowed in preprocessing decisions\n",
        "\n",
        "3. üìä ENHANCE GENERALIZATION\n",
        "   - Reduce overfitting through robust statistical methods\n",
        "   - Ensure preprocessing works on unseen data\n",
        "\n",
        "4. üîÑ DUAL-TASK COMPATIBILITY\n",
        "   - Single pipeline serves both regression AND classification\n",
        "   - No task-specific compromises\n",
        "\n",
        "5. ‚ö° IMPROVE MODEL STABILITY\n",
        "   - Reduce variance in cross-validation performance\n",
        "   - Create consistent, reliable transformations\n",
        "\n",
        "6. üß† MAXIMIZE LEARNING CAPACITY\n",
        "   - Create features that are EASY for models to learn from\n",
        "   - Remove statistical barriers to pattern recognition\n",
        "\n",
        "APPROACH:\n",
        "- Analyze each feature's statistical properties\n",
        "- Choose transformations based on DATA CHARACTERISTICS\n",
        "- Justify every decision with MODEL PERFORMANCE IMPACT\n",
        "- Maintain REPRODUCIBILITY and SCALABILITY\n",
        "\n",
        "üéØ GOAL: Transform data to maximize model learning capacity while minimizing error sources"
      ],
      "metadata": {
        "id": "4seLXrhOZd4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Section 4: STEP-BY-STEP PREPROCESSING PIPELINE**"
      ],
      "metadata": {
        "id": "yQOXT8ClaBgg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 6.1: DATA TYPE CORRECTION\n",
        "\n",
        "**What we cover here:** Converting object-type columns to appropriate numeric types to enable mathematical operations\n",
        "\n",
        "<br>\n",
        "\n",
        "**WHY THIS STEP?**\n",
        "\n",
        "Machine learning algorithms require NUMERIC inputs. Text-based columns cause:\n",
        "- ‚ùå Training failures in scikit-learn\n",
        "- ‚ùå Loss of ordinal relationships\n",
        "- ‚ùå Inability to compute mathematical operations\n",
        "\n",
        "APPROACH:\n",
        "- Identify non-categorical numeric columns\n",
        "- Convert using pd.to_numeric with error handling\n",
        "- Preserve intentional categorical columns for later encoding"
      ],
      "metadata": {
        "id": "LoOhrMZ_aOIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4.1 - Data Type Correction\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"STEP 4.1: DATA TYPE CORRECTION\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\"\"\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "# Define categorical columns to preserve\n",
        "categorical_cols = [\n",
        "    'Country_Name',\n",
        "    'Political_System_Type',\n",
        "    'Economic_Classification',\n",
        "    'Language_Diversity_Level',\n",
        "    'Regulation_Strictness',\n",
        "    'Happiness_Index',\n",
        "    'Space_Tech_Level',\n",
        "    'Nuclear_Power_Status'\n",
        "]\n",
        "\n",
        "# Identify numeric candidate columns\n",
        "numeric_candidate_cols = [\n",
        "    col for col in df.columns\n",
        "    if col not in categorical_cols\n",
        "]\n",
        "\n",
        "print(f\"\\nConverting {len(numeric_candidate_cols)} columns to numeric type...\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Convert to numeric, coercing errors to NaN\n",
        "converted_count = 0\n",
        "for col in numeric_candidate_cols:\n",
        "    original_dtype = df[col].dtype\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "    converted_dtype = df[col].dtype\n",
        "\n",
        "    if original_dtype != converted_dtype:\n",
        "        converted_count += 1\n",
        "        print(f\"  ‚úì {col}: {original_dtype} ‚Üí {converted_dtype}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Data type correction completed!\")\n",
        "print(f\"   Converted: {converted_count} columns\")\n",
        "print(f\"\\nRemaining object columns (intentional):\")\n",
        "print(df.select_dtypes(include='object').columns.tolist())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suam9fHSZNQD",
        "outputId": "39702095-1732-4d80-befe-9d096c3bb576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "STEP 4.1: DATA TYPE CORRECTION\n",
            "================================================================================\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Converting 25 columns to numeric type...\n",
            "--------------------------------------------------------------------------------\n",
            "  ‚úì Population: object ‚Üí float64\n",
            "  ‚úì GDP_per_Capita_USD: object ‚Üí float64\n",
            "  ‚úì Carbon_Footprint: object ‚Üí float64\n",
            "  ‚úì Medical_Doctors_per_1000: object ‚Üí float64\n",
            "  ‚úì Number_of_Patents: object ‚Üí float64\n",
            "\n",
            "‚úÖ Data type correction completed!\n",
            "   Converted: 5 columns\n",
            "\n",
            "Remaining object columns (intentional):\n",
            "['Country_Name', 'Language_Diversity_Level', 'Political_System_Type', 'Economic_Classification', 'Space_Tech_Level', 'Nuclear_Power_Status', 'Regulation_Strictness', 'Happiness_Index']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ MODEL IMPACT:\n",
        "- ‚úÖ Enables mathematical operations on all numeric features\n",
        "- ‚úÖ Prevents runtime errors during training\n",
        "- ‚úÖ Allows proper statistical transformations"
      ],
      "metadata": {
        "id": "pdhfoFlPbgfE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP 6.2: BINARY ENCODING\n",
        "\n",
        "**What we cover here:** Converting Yes/No binary features to 0/1 numeric encoding.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "**WHY BINARY ENCODING?**\n",
        "\n",
        "For true binary features (Yes/No, True/False):\n",
        "- ‚úÖ Simple and interpretable (0 or 1)\n",
        "- ‚úÖ No dimensionality increase\n",
        "- ‚úÖ Direct mathematical meaning\n",
        "\n",
        "**WHY NOT ONE-HOT?**\n",
        "\n",
        "- ‚ùå Creates unnecessary redundancy (2 columns for 1 feature)\n",
        "- ‚ùå Wastes computational resources\n",
        "- ‚ùå Introduces multicollinearity"
      ],
      "metadata": {
        "id": "JjIsTQmQaYO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4.2 - Binary Encoding\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"STEP 4.2: BINARY ENCODING (Nuclear Power Status)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\nOriginal Nuclear Power Status distribution:\")\n",
        "print(df['Nuclear_Power_Status'].value_counts())\n",
        "\n",
        "# Map Yes/No to 1/0\n",
        "df['Nuclear_Power_Status'] = (\n",
        "    df['Nuclear_Power_Status']\n",
        "    .str.strip()\n",
        "    .map({'No': 0, 'Yes': 1})\n",
        ")\n",
        "\n",
        "print(\"\\nEncoded Nuclear Power Status distribution:\")\n",
        "print(df['Nuclear_Power_Status'].value_counts().sort_index())\n",
        "\n",
        "# Verify no unmapped values\n",
        "unmapped = df['Nuclear_Power_Status'].isnull().sum()\n",
        "print(f\"\\n‚úÖ Unmapped values: {unmapped}\")\n",
        "\n",
        "if unmapped == 0:\n",
        "    print(\"‚úÖ Binary encoding completed successfully!\")\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è Warning: {unmapped} values could not be mapped\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZsGqXJkaLv1",
        "outputId": "d9a70713-68ef-4f66-ffd4-540d5bdd7530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "STEP 4.2: BINARY ENCODING (Nuclear Power Status)\n",
            "================================================================================\n",
            "\n",
            "Original Nuclear Power Status distribution:\n",
            "Nuclear_Power_Status\n",
            "No     157\n",
            "Yes     35\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Encoded Nuclear Power Status distribution:\n",
            "Nuclear_Power_Status\n",
            "0    157\n",
            "1     35\n",
            "Name: count, dtype: int64\n",
            "\n",
            "‚úÖ Unmapped values: 0\n",
            "‚úÖ Binary encoding completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ MODEL IMPACT:\n",
        "- ‚úÖ Clean binary feature ready for any ML algorithm\n",
        "- ‚úÖ Interpretable: 1 = Has nuclear power, 0 = Doesn't have\n",
        "- ‚úÖ No information loss"
      ],
      "metadata": {
        "id": "CZqWAzC9a_7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# STEP 4.3: ORDINAL ENCODING\n",
        "\n",
        "\n",
        "\n",
        "What we cover here:\n",
        "Encoding ordered categorical variables into numeric ranks\n",
        "while preserving their natural hierarchy.\n",
        "\n",
        "<br>\n",
        "\n",
        "### WHY ORDINAL ENCODING (NOT ONE-HOT)?\n",
        "\n",
        "For features with natural ordering (Low < Medium < High):\n",
        "\n",
        "Method Comparison:\n",
        "                                            \n",
        "- One-Hot Encoding:    Destroys order, creates extra cols     ‚ùå\n",
        "- Label Encoding:      Arbitrary alphabetical assignment     ‚ùå\n",
        "- Ordinal Mapping:      Preserves true hierarchy              ‚úÖ\n",
        "                     (1 < 2 < 3 < 4)\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "FEATURES TO ENCODE\n",
        "\n",
        " 1. Regulation_Strictness: Very Low ‚Üí Low ‚Üí Medium ‚Üí High ‚Üí Very High\n",
        " 2. Happiness_Index: Unhappy ‚Üí Neutral ‚Üí Happy ‚Üí Very Happy\n",
        " 3. Space_Tech_Level: Beginner ‚Üí Intermediate ‚Üí Advanced ‚Üí Elite\n"
      ],
      "metadata": {
        "id": "rNX0QG4hbOAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordinal Encoding - Regulation Strictness\n",
        "\n",
        "print(\"\\nüìã ENCODING: Regulation Strictness\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "regulation_map = {\n",
        "    'Very Low': 1,\n",
        "    'Low': 2,\n",
        "    'Medium': 3,\n",
        "    'High': 4,\n",
        "    'Very High': 5\n",
        "}\n",
        "\n",
        "print(f\"Mapping: {regulation_map}\")\n",
        "\n",
        "df['Regulation_Strictness_Ordinal'] = (\n",
        "    df['Regulation_Strictness']\n",
        "    .str.strip()\n",
        "    .map(regulation_map)\n",
        ")\n",
        "\n",
        "print(\"\\nOriginal distribution:\")\n",
        "print(df['Regulation_Strictness'].value_counts().sort_index())\n",
        "\n",
        "print(\"\\nEncoded distribution:\")\n",
        "print(df['Regulation_Strictness_Ordinal'].value_counts().sort_index())\n",
        "\n",
        "unmapped = df['Regulation_Strictness_Ordinal'].isnull().sum()\n",
        "print(f\"\\n‚úÖ Unmapped values: {unmapped}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT9LFTCcaVhB",
        "outputId": "bfc04944-d603-4fab-bcff-d7a96217a4d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìã ENCODING: Regulation Strictness\n",
            "--------------------------------------------------------------------------------\n",
            "Mapping: {'Very Low': 1, 'Low': 2, 'Medium': 3, 'High': 4, 'Very High': 5}\n",
            "\n",
            "Original distribution:\n",
            "Regulation_Strictness\n",
            "High         37\n",
            "Low          53\n",
            "Medium       91\n",
            "Very High     9\n",
            "Very Low      2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Encoded distribution:\n",
            "Regulation_Strictness_Ordinal\n",
            "1     2\n",
            "2    53\n",
            "3    91\n",
            "4    37\n",
            "5     9\n",
            "Name: count, dtype: int64\n",
            "\n",
            "‚úÖ Unmapped values: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordinal Encoding - Happiness Index\n",
        "\n",
        "print(\"\\nüìã ENCODING: Happiness Index\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "happiness_map = {\n",
        "    'Unhappy': 1,\n",
        "    'Neutral': 2,\n",
        "    'Happy': 3,\n",
        "    'Very Happy': 4\n",
        "}\n",
        "\n",
        "print(f\"Mapping: {happiness_map}\")\n",
        "\n",
        "df['Happiness_Index_Ordinal'] = (\n",
        "    df['Happiness_Index']\n",
        "    .str.strip()\n",
        "    .map(happiness_map)\n",
        ")\n",
        "\n",
        "print(\"\\nOriginal distribution:\")\n",
        "print(df['Happiness_Index'].value_counts().sort_index())\n",
        "\n",
        "print(\"\\nEncoded distribution:\")\n",
        "print(df['Happiness_Index_Ordinal'].value_counts().sort_index())\n",
        "\n",
        "unmapped = df['Happiness_Index_Ordinal'].isnull().sum()\n",
        "print(f\"\\n‚úÖ Unmapped values: {unmapped}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRnrzKwpb8Td",
        "outputId": "d6b089af-85f4-4415-fff3-8378953fcdec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìã ENCODING: Happiness Index\n",
            "--------------------------------------------------------------------------------\n",
            "Mapping: {'Unhappy': 1, 'Neutral': 2, 'Happy': 3, 'Very Happy': 4}\n",
            "\n",
            "Original distribution:\n",
            "Happiness_Index\n",
            "Happy         105\n",
            "Unhappy        59\n",
            "Very Happy     28\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Encoded distribution:\n",
            "Happiness_Index_Ordinal\n",
            "1     59\n",
            "3    105\n",
            "4     28\n",
            "Name: count, dtype: int64\n",
            "\n",
            "‚úÖ Unmapped values: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordinal Encoding - Space Technology Level\n",
        "\n",
        "print(\"\\nüìã ENCODING: Space Technology Level\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "space_tech_map = {\n",
        "    'Beginner': 1,\n",
        "    'Intermediate': 2,\n",
        "    'Advanced': 3,\n",
        "    'Elite': 4\n",
        "}\n",
        "\n",
        "print(f\"Mapping: {space_tech_map}\")\n",
        "\n",
        "df['Space_Tech_Level_Ordinal'] = (\n",
        "    df['Space_Tech_Level']\n",
        "    .str.strip()\n",
        "    .map(space_tech_map)\n",
        ")\n",
        "\n",
        "print(\"\\nOriginal distribution:\")\n",
        "print(df['Space_Tech_Level'].value_counts().sort_index())\n",
        "\n",
        "print(\"\\nEncoded distribution:\")\n",
        "print(df['Space_Tech_Level_Ordinal'].value_counts().sort_index())\n",
        "\n",
        "unmapped = df['Space_Tech_Level_Ordinal'].isnull().sum()\n",
        "print(f\"\\n‚úÖ Unmapped values: {unmapped}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCeOIbTacGoW",
        "outputId": "9810e410-17f1-4091-c0a8-0cf9cbed86fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìã ENCODING: Space Technology Level\n",
            "--------------------------------------------------------------------------------\n",
            "Mapping: {'Beginner': 1, 'Intermediate': 2, 'Advanced': 3, 'Elite': 4}\n",
            "\n",
            "Original distribution:\n",
            "Space_Tech_Level\n",
            "Advanced        38\n",
            "Beginner        52\n",
            "Elite           29\n",
            "Intermediate    73\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Encoded distribution:\n",
            "Space_Tech_Level_Ordinal\n",
            "1    52\n",
            "2    73\n",
            "3    38\n",
            "4    29\n",
            "Name: count, dtype: int64\n",
            "\n",
            "‚úÖ Unmapped values: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordinal Encoding Verification\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ORDINAL ENCODING VERIFICATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "ordinal_checks = [\n",
        "    ('Regulation_Strictness_Ordinal', regulation_map),\n",
        "    ('Happiness_Index_Ordinal', happiness_map),\n",
        "    ('Space_Tech_Level_Ordinal', space_tech_map)\n",
        "]\n",
        "\n",
        "all_success = True\n",
        "for col, mapping in ordinal_checks:\n",
        "    unmapped = df[col].isnull().sum()\n",
        "    status = \"‚úÖ PASS\" if unmapped == 0 else f\"‚ö†Ô∏è FAIL ({unmapped} unmapped)\"\n",
        "    print(f\"  {col}: {status}\")\n",
        "    if unmapped > 0:\n",
        "        all_success = False\n",
        "\n",
        "if all_success:\n",
        "    print(\"\\n‚úÖ All ordinal encodings completed successfully!\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è Some values could not be mapped - review data quality\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mlb6H6fCdbd7",
        "outputId": "9c42cd8e-43ce-4d1e-9419-44a99a434771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ORDINAL ENCODING VERIFICATION\n",
            "================================================================================\n",
            "  Regulation_Strictness_Ordinal: ‚úÖ PASS\n",
            "  Happiness_Index_Ordinal: ‚úÖ PASS\n",
            "  Space_Tech_Level_Ordinal: ‚úÖ PASS\n",
            "\n",
            "‚úÖ All ordinal encodings completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ MODEL IMPACT:\n",
        "- ‚úÖ Preserves ranking information ‚Üí Regression learns monotonic relationships\n",
        "- ‚úÖ Maintains interpretability ‚Üí Higher value = higher level\n",
        "- ‚úÖ Enables meaningful boundaries ‚Üí Classification learns natural thresholds\n",
        "- ‚úÖ Reduces dimensionality ‚Üí 1 column instead of 4 (vs. One-Hot)"
      ],
      "metadata": {
        "id": "KXmSp9asdiHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 4.4: PERCENTAGE SCALE STANDARDIZATION**\n",
        "\n",
        "**What we cover here:** Unifying percentage features stored inconsistently (as decimals 0-1 or as percentages 0-100) into a consistent 0-100 scale\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "THE PROBLEM:\n",
        "\n",
        "Percentage features stored INCONSISTENTLY:\n",
        "- Some as decimals: 0.85 (representing 85%)\n",
        "- Some as percentages: 85.0 (representing 85%)\n",
        "\n",
        "This creates SCALE AMBIGUITY that confuses models.\n",
        "\n",
        "WHY STANDARDIZE TO 0-100 SCALE?\n",
        "- ‚úÖ Interpretability: 85.5 clearly means 85.5%\n",
        "- ‚úÖ Consistency: All percentages on same scale\n",
        "- ‚úÖ No information loss: Just rescaling, not transformation\n",
        "- ‚úÖ Domain alignment: Matches business understanding\n",
        "\n",
        "APPROACH:\n",
        "- If value ‚â§ 1 ‚Üí Multiply by 100\n",
        "- If value > 1 ‚Üí Keep as is"
      ],
      "metadata": {
        "id": "Vc7G9WEMdwwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# ============================================================\n",
        "# STEP: STANDARDIZE PERCENTAGE FEATURES TO [0, 100] SCALE\n",
        "# ============================================================\n",
        "\n",
        "# Define intended percentage columns\n",
        "intended_percentage_cols = [\n",
        "    'Literacy_Rate_pct',\n",
        "    'Internet_Access_pct',\n",
        "    'Higher_Education_Rate',\n",
        "    'Gender_Equality_Index',\n",
        "    'Migration_Rate',\n",
        "    'Immigration_Rate',\n",
        "    'Defence_expenditure_on_GDP',\n",
        "    'Govt_Education_Expenditure_pct_GDP',\n",
        "    'R_and_D_Expenditure_pct_GDP',\n",
        "    'Health_Expenditure_pct_GDP'\n",
        "]\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Filter to columns that actually exist in the dataset\n",
        "# ------------------------------------------------------------\n",
        "percentage_cols = [col for col in intended_percentage_cols if col in df.columns]\n",
        "missing_cols = set(intended_percentage_cols) - set(percentage_cols)\n",
        "\n",
        "print(f\"\\nProcessing {len(percentage_cols)} percentage columns...\")\n",
        "if missing_cols:\n",
        "    print(f\"‚ö†Ô∏è Skipped (not in dataset): {missing_cols}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# Standardization Logic:\n",
        "# Multiply by 100 if values are in [0, 1] range\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"Standardizing scale to [0, 100] range...\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for col in percentage_cols:\n",
        "    # Count values that need rescaling\n",
        "    needs_rescaling = ((df[col].notna()) & (df[col] <= 1)).sum()\n",
        "\n",
        "    if needs_rescaling > 0:\n",
        "        print(f\"  ‚Ä¢ {col}: Rescaling {needs_rescaling} values from [0, 1] ‚Üí [0, 100]\")\n",
        "\n",
        "    # Apply rescaling\n",
        "    df[col] = np.where(\n",
        "        df[col].notna() & (df[col] <= 1),\n",
        "        df[col] * 100,\n",
        "        df[col]\n",
        "    )\n",
        "\n",
        "# Verify standardization\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"POST-STANDARDIZATION VERIFICATION\")\n",
        "print(\"=\" * 80)\n",
        "print(df[percentage_cols].describe().loc[['min', 'max']])\n",
        "print(\"\\n‚úÖ All percentage features now on 0-100 scale!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AONn75VodhJI",
        "outputId": "9a5d1b47-d50a-4fd6-b7ca-782474b80cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing 9 percentage columns...\n",
            "‚ö†Ô∏è Skipped (not in dataset): {'Health_Expenditure_pct_GDP'}\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Standardizing scale to [0, 100] range...\n",
            "--------------------------------------------------------------------------------\n",
            "  ‚Ä¢ Literacy_Rate_pct: Rescaling 155 values from [0, 1] ‚Üí [0, 100]\n",
            "  ‚Ä¢ Internet_Access_pct: Rescaling 144 values from [0, 1] ‚Üí [0, 100]\n",
            "  ‚Ä¢ Higher_Education_Rate: Rescaling 143 values from [0, 1] ‚Üí [0, 100]\n",
            "  ‚Ä¢ Gender_Equality_Index: Rescaling 155 values from [0, 1] ‚Üí [0, 100]\n",
            "  ‚Ä¢ Migration_Rate: Rescaling 149 values from [0, 1] ‚Üí [0, 100]\n",
            "  ‚Ä¢ Immigration_Rate: Rescaling 151 values from [0, 1] ‚Üí [0, 100]\n",
            "  ‚Ä¢ Defence_expenditure_on_GDP: Rescaling 169 values from [0, 1] ‚Üí [0, 100]\n",
            "  ‚Ä¢ Govt_Education_Expenditure_pct_GDP: Rescaling 159 values from [0, 1] ‚Üí [0, 100]\n",
            "  ‚Ä¢ R_and_D_Expenditure_pct_GDP: Rescaling 158 values from [0, 1] ‚Üí [0, 100]\n",
            "\n",
            "================================================================================\n",
            "POST-STANDARDIZATION VERIFICATION\n",
            "================================================================================\n",
            "     Literacy_Rate_pct  Internet_Access_pct  Higher_Education_Rate  \\\n",
            "min                0.0                  0.0                    0.0   \n",
            "max              100.0                100.0                  100.0   \n",
            "\n",
            "     Gender_Equality_Index  Migration_Rate  Immigration_Rate  \\\n",
            "min                    0.0        0.000000          0.000000   \n",
            "max                  100.0       43.930764         47.356981   \n",
            "\n",
            "     Defence_expenditure_on_GDP  Govt_Education_Expenditure_pct_GDP  \\\n",
            "min                    0.000000                            0.000000   \n",
            "max                   65.591701                           18.119829   \n",
            "\n",
            "     R_and_D_Expenditure_pct_GDP  \n",
            "min                     0.000000  \n",
            "max                    98.198704  \n",
            "\n",
            "‚úÖ All percentage features now on 0-100 scale!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ MODEL IMPACT:\n",
        "- ‚úÖ Eliminates scale ambiguity ‚Üí Models interpret features correctly\n",
        "- ‚úÖ Improves comparability ‚Üí All percentages directly comparable\n",
        "- ‚úÖ Enhances feature importance ‚Üí True magnitude relationships preserved"
      ],
      "metadata": {
        "id": "qNJxbQZ1-0O8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **STEP 4.5: OUTLIER TREATMENT (IQR CAPPING)**\n",
        "\n",
        "**What we cover here:** Capping extreme outliers using IQR method (Winsorization) to reduce their influence without deleting valuable data points\n",
        "\n",
        "\n",
        "**WHY IQR CAPPING (WINSORIZATION)?**\n",
        "- ‚úÖ Caps influence without deletion\n",
        "- ‚úÖ Preserves data points and statistical power\n",
        "- ‚úÖ Maintains ranking relationships\n",
        "- ‚úÖ Reduces overfitting to extreme cases\n",
        "- ‚úÖ Keeps full sample size\n",
        "\n",
        "\n",
        "METHOD:\n",
        "\n",
        "Cap at Q3 + 1.5 √ó IQR (upper outliers only)"
      ],
      "metadata": {
        "id": "shClBEn__Qdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4.5 - Outlier Treatment\n",
        "\n",
        "\n",
        "# Define function for IQR-based upper capping\n",
        "def iqr_cap(series):\n",
        "    \"\"\"Cap values at Q3 + 1.5*IQR (upper outliers only)\"\"\"\n",
        "    Q1 = series.quantile(0.25)\n",
        "    Q3 = series.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    upper_cap = Q3 + 1.5 * IQR\n",
        "    return series.clip(upper=upper_cap)\n",
        "\n",
        "# Identify heavy-tailed features requiring capping\n",
        "heavy_tailed_cols = [\n",
        "    'Population',\n",
        "    'GDP_per_Capita_USD',\n",
        "    'Carbon_Footprint',\n",
        "    'Number_of_Patents',\n",
        "    'Olympic_Medals_Count',\n",
        "    'Number_of_Startups'\n",
        "]\n",
        "\n",
        "print(f\"\\nApplying IQR capping to {len(heavy_tailed_cols)} heavy-tailed features...\")\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"Outlier Summary (values beyond Q3 + 1.5*IQR):\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"{'Feature':<35} {'Outliers Capped':>20}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for col in heavy_tailed_cols:\n",
        "    if col in df.columns:\n",
        "        # Calculate cap threshold\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        cap = Q3 + 1.5 * IQR\n",
        "\n",
        "        # Count outliers\n",
        "        outlier_count = (df[col] > cap).sum()\n",
        "\n",
        "        # Apply capping\n",
        "        df[col] = iqr_cap(df[col])\n",
        "\n",
        "        print(f\"{col:<35} {outlier_count:>20,}\")\n",
        "\n",
        "print(\"\\n‚úÖ Outlier capping completed!\")\n",
        "\n",
        "# Verify ranges after capping\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"POST-CAPPING VERIFICATION\")\n",
        "print(\"=\" * 80)\n",
        "print(df[heavy_tailed_cols].describe().loc[['min', 'max']])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyo0aNUg-pwX",
        "outputId": "92189577-b524-4207-ef71-c5f4f8b842f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Applying IQR capping to 6 heavy-tailed features...\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Outlier Summary (values beyond Q3 + 1.5*IQR):\n",
            "--------------------------------------------------------------------------------\n",
            "Feature                                  Outliers Capped\n",
            "--------------------------------------------------------------------------------\n",
            "Population                                             0\n",
            "GDP_per_Capita_USD                                     2\n",
            "Carbon_Footprint                                       1\n",
            "Number_of_Patents                                      3\n",
            "Olympic_Medals_Count                                   2\n",
            "Number_of_Startups                                     4\n",
            "\n",
            "‚úÖ Outlier capping completed!\n",
            "\n",
            "================================================================================\n",
            "POST-CAPPING VERIFICATION\n",
            "================================================================================\n",
            "      Population  GDP_per_Capita_USD  Carbon_Footprint  Number_of_Patents  \\\n",
            "min     241004.0               500.0          1.000000              0.000   \n",
            "max  195143218.0             36881.0         17.556179          32169.625   \n",
            "\n",
            "     Olympic_Medals_Count  Number_of_Startups  \n",
            "min                   0.0                0.00  \n",
            "max                 180.0            27129.25  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ MODEL IMPACT:\n",
        "- ‚úÖ Stabilizes training by reducing extreme gradient updates\n",
        "- ‚úÖ Improves CV consistency across folds\n",
        "- ‚úÖ Reduces RMSE spikes from overfitting to outliers\n",
        "- ‚úÖ Maintains full sample size for statistical power\n",
        "- ‚úÖ Preserves ordering for rank-based features"
      ],
      "metadata": {
        "id": "AaOK8BJR_62X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **STEP 4.6: DOMAIN-SPECIFIC BOUND ENFORCEMENT**\n",
        "\n",
        "**What we cover here:** Enforcing logical constraints (percentages must be 0-100%, indices must be non-negative) to correct data entry errors\n",
        "\n",
        "\n",
        "**WHY ENFORCE LOGICAL BOUNDS?**\n",
        "\n",
        "Some features have PHYSICALLY MEANINGFUL ranges:\n",
        "- Percentages: Must be 0-100%\n",
        "- Indices: Must be non-negative\n",
        "\n",
        "Values outside these ranges indicate:\n",
        "- ‚ùå Data entry errors\n",
        "- ‚ùå Measurement issues\n",
        "- ‚ùå Unit conversion problems\n",
        "\n",
        "APPROACH:\n",
        "1. Clip percentages to [0, 100]\n",
        "2. Clip indices to [0, ‚àû)\n",
        "3. Preserve relative magnitudes within valid range\n"
      ],
      "metadata": {
        "id": "27iXDBwbAHVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4.6 - Domain-Specific Bounds\n",
        "\n",
        "\n",
        "# Enforce 0-100% bounds on percentage/rate features\n",
        "print(\"\\nüìè Enforcing [0, 100] bounds on percentage features...\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "percentage_rate_cols = [\n",
        "    'Literacy_Rate_pct',\n",
        "    'Internet_Access_pct',\n",
        "    'Higher_Education_Rate',\n",
        "    'Govt_Education_Expenditure_pct_GDP',\n",
        "    'Health_Expenditure_pct_GDP',\n",
        "    'R_and_D_Expenditure_pct_GDP',\n",
        "    'Migration_Rate',\n",
        "    'Immigration_Rate',\n",
        "    'Defence_expenditure_on_GDP'\n",
        "]\n",
        "\n",
        "violations_found = False\n",
        "for col in percentage_rate_cols:\n",
        "    if col in df.columns:\n",
        "        below_zero = (df[col] < 0).sum()\n",
        "        above_hundred = (df[col] > 100).sum()\n",
        "\n",
        "        if below_zero > 0 or above_hundred > 0:\n",
        "            violations_found = True\n",
        "            print(f\"  ‚Ä¢ {col}: {below_zero} below 0, {above_hundred} above 100\")\n",
        "\n",
        "        # Apply clipping\n",
        "        df[col] = df[col].clip(lower=0, upper=100)\n",
        "\n",
        "if not violations_found:\n",
        "    print(\"  ‚úì No violations found - all percentages within valid range\")\n",
        "else:\n",
        "    print(\"\\n  ‚úÖ Violations corrected via clipping\")\n",
        "\n",
        "# Enforce non-negative bounds on index features\n",
        "print(\"\\nüìè Enforcing non-negative bounds on index features...\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "index_cols = [\n",
        "    'HDI_Index',\n",
        "    'Gender_Equality_Index'\n",
        "]\n",
        "\n",
        "violations_found = False\n",
        "for col in index_cols:\n",
        "    if col in df.columns:\n",
        "        below_zero = (df[col] < 0).sum()\n",
        "\n",
        "        if below_zero > 0:\n",
        "            violations_found = True\n",
        "            print(f\"  ‚Ä¢ {col}: {below_zero} negative values\")\n",
        "\n",
        "        # Apply clipping to ensure non-negative\n",
        "        df[col] = df[col].clip(lower=0)\n",
        "\n",
        "if not violations_found:\n",
        "    print(\"  ‚úì No violations found - all indices non-negative\")\n",
        "else:\n",
        "    print(\"\\n  ‚úÖ Violations corrected via clipping\")\n",
        "\n",
        "print(\"\\n‚úÖ Domain-specific bound enforcement completed!\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WtX2IGgl_3LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ MODEL IMPACT:\n",
        "- ‚úÖ Prevents nonsensical predictions (e.g., -10% literacy rate)\n",
        "- ‚úÖ Aligns with domain knowledge ‚Üí Improves trustworthiness\n",
        "- ‚úÖ Reduces noise from data entry errors\n",
        "- ‚úÖ Stabilizes learning by eliminating impossible values"
      ],
      "metadata": {
        "id": "SS5TsKRfGL4s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **STEP 4.7: MISSING VALUE IMPUTATION**\n",
        "\n",
        "**What we cover here:** Strategically filling missing values using median for continuous features, mode for categorical features, and 'Unknown' for nominal categories\n",
        "\n",
        "<br>\n",
        "\n",
        "WHY MEDIAN IMPUTATION FOR CONTINUOUS FEATURES?\n",
        "\n",
        "METHOD COMPARISON:\n",
        "Mean: Sensitive to skewness and outliers ‚ùå                 \n",
        "\n",
        "Mode: Not meaningful for continuous data ‚ùå              \n",
        "\n",
        "KNN: Computationally expensive, risk of overfitting ‚ùå           \n",
        "\n",
        "Median: Robust to outliers,stable, interpretable‚úÖ         \n",
        "\n",
        "<br>\n",
        "\n",
        "IMPUTATION STRATEGY BY FEATURE TYPE:\n",
        "1. Continuous (percentages, rates) ‚Üí MEDIAN\n",
        "2. Ordinal (encoded levels) ‚Üí MODE\n",
        "3. Binary (0/1) ‚Üí MODE\n",
        "4. Nominal (categories) ‚Üí 'Unknown' category\n"
      ],
      "metadata": {
        "id": "y_rZSjlSGW32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6.7 - Missing Value Imputation Strategy\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"STEP 6.7: MISSING VALUE IMPUTATION (Strategic Approach)\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\"\"\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "# Check current missing value status\n",
        "print(\"\\nMissing values BEFORE imputation:\")\n",
        "print(\"-\" * 80)\n",
        "missing_summary = (\n",
        "    df.isna()\n",
        "    .sum()\n",
        "    .reset_index()\n",
        "    .rename(columns={'index': 'Column', 0: 'Missing_Count'})\n",
        "    .query(\"Missing_Count > 0\")\n",
        "    .sort_values(by='Missing_Count', ascending=False)\n",
        ")\n",
        "\n",
        "if len(missing_summary) > 0:\n",
        "    print(missing_summary.to_string(index=False))\n",
        "    print(f\"\\nTotal missing values: {missing_summary['Missing_Count'].sum():,}\")\n",
        "else:\n",
        "    print(\"‚úÖ No missing values found!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICf1PcuJGG9C",
        "outputId": "3adde129-d9c8-4929-a893-820f7d6d3109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "STEP 6.7: MISSING VALUE IMPUTATION (Strategic Approach)\n",
            "================================================================================\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Missing values BEFORE imputation:\n",
            "--------------------------------------------------------------------------------\n",
            "                            Column  Missing_Count\n",
            "          Medical_Doctors_per_1000             18\n",
            "                    Migration_Rate             16\n",
            "                  Immigration_Rate             14\n",
            "             Higher_Education_Rate             14\n",
            "       R_and_D_Expenditure_pct_GDP             12\n",
            "               Internet_Access_pct             12\n",
            "                        Population              6\n",
            "Govt_Education_Expenditure_pct_GDP              6\n",
            "                GDP_per_Capita_USD              5\n",
            "                  Carbon_Footprint              3\n",
            "                 Number_of_Patents              2\n",
            "\n",
            "Total missing values: 108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute Percentage/Rate Features\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìä IMPUTING: Percentage/Rate Features with MEDIAN\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "pct_columns = [\n",
        "    'Literacy_Rate_pct',\n",
        "    'Internet_Access_pct',\n",
        "    'Higher_Education_Rate',\n",
        "    'Govt_Education_Expenditure_pct_GDP',\n",
        "    'Unemployment_Rate_pct'\n",
        "]\n",
        "\n",
        "imputed_count = 0\n",
        "for col in pct_columns:\n",
        "    if col in df.columns:\n",
        "        missing_before = df[col].isnull().sum()\n",
        "        if missing_before > 0:\n",
        "            median_value = df[col].median()\n",
        "            df[col] = df[col].fillna(median_value)\n",
        "            imputed_count += 1\n",
        "            print(f\"  ‚úì {col}\")\n",
        "            print(f\"    Missing: {missing_before} | Median: {median_value:.2f}\")\n",
        "\n",
        "if imputed_count == 0:\n",
        "    print(\"  ‚úì No missing values in percentage/rate features\")\n",
        "\n",
        "print(f\"\\n‚úÖ Imputed {imputed_count} percentage/rate features\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT4qWiDxHJVg",
        "outputId": "6ef1eab6-f971-4ab3-ae46-7960ae43f50a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üìä IMPUTING: Percentage/Rate Features with MEDIAN\n",
            "================================================================================\n",
            "  ‚úì Internet_Access_pct\n",
            "    Missing: 12 | Median: 39.32\n",
            "  ‚úì Higher_Education_Rate\n",
            "    Missing: 14 | Median: 19.90\n",
            "  ‚úì Govt_Education_Expenditure_pct_GDP\n",
            "    Missing: 6 | Median: 3.41\n",
            "\n",
            "‚úÖ Imputed 3 percentage/rate features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute Economic Indicators\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìä IMPUTING: Economic Indicators with MEDIAN\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "economic_cols = [\n",
        "    'R_and_D_Expenditure_pct_GDP',\n",
        "    'Number_of_Patents',\n",
        "    'Carbon_Footprint'\n",
        "]\n",
        "\n",
        "imputed_count = 0\n",
        "for col in economic_cols:\n",
        "    if col in df.columns:\n",
        "        missing_before = df[col].isnull().sum()\n",
        "        if missing_before > 0:\n",
        "            median_value = df[col].median()\n",
        "            df[col] = df[col].fillna(median_value)\n",
        "            imputed_count += 1\n",
        "            print(f\"  ‚úì {col}\")\n",
        "            print(f\"    Missing: {missing_before} | Median: {median_value:.2f}\")\n",
        "\n",
        "if imputed_count == 0:\n",
        "    print(\"  ‚úì No missing values in economic indicators\")\n",
        "\n",
        "print(f\"\\n‚úÖ Imputed {imputed_count} economic indicator features\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-PDYvu5HIIU",
        "outputId": "9d9db2a8-b390-4b10-c328-061d0abf2b7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üìä IMPUTING: Economic Indicators with MEDIAN\n",
            "================================================================================\n",
            "  ‚úì R_and_D_Expenditure_pct_GDP\n",
            "    Missing: 12 | Median: 2.17\n",
            "  ‚úì Number_of_Patents\n",
            "    Missing: 2 | Median: 12638.50\n",
            "  ‚úì Carbon_Footprint\n",
            "    Missing: 3 | Median: 7.32\n",
            "\n",
            "‚úÖ Imputed 3 economic indicator features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute Healthcare Feature\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìä IMPUTING: Healthcare Feature with MEDIAN\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "missing_before = df['Medical_Doctors_per_1000'].isnull().sum()\n",
        "if missing_before > 0:\n",
        "    median_value = df['Medical_Doctors_per_1000'].median()\n",
        "    df['Medical_Doctors_per_1000'] = df['Medical_Doctors_per_1000'].fillna(median_value)\n",
        "    print(f\"  ‚úì Medical_Doctors_per_1000\")\n",
        "    print(f\"    Missing: {missing_before} | Median: {median_value:.2f}\")\n",
        "else:\n",
        "    print(\"  ‚úì No missing values in Medical_Doctors_per_1000\")\n",
        "\n",
        "print(\"\\n‚úÖ Healthcare feature imputation completed\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWEYkAluIK4W",
        "outputId": "7d746232-9c75-48b6-d164-c417f7301912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üìä IMPUTING: Healthcare Feature with MEDIAN\n",
            "================================================================================\n",
            "  ‚úì Medical_Doctors_per_1000\n",
            "    Missing: 18 | Median: 1.67\n",
            "\n",
            "‚úÖ Healthcare feature imputation completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute Ordinal Features\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìä IMPUTING: Ordinal Features with MODE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "ordinal_cols = [\n",
        "    'Regulation_Strictness_Ordinal',\n",
        "    'Happiness_Index_Ordinal'\n",
        "]\n",
        "\n",
        "imputed_count = 0\n",
        "for col in ordinal_cols:\n",
        "    if col in df.columns:\n",
        "        missing_before = df[col].isnull().sum()\n",
        "        if missing_before > 0:\n",
        "            mode_value = df[col].mode()[0]\n",
        "            df[col] = df[col].fillna(mode_value)\n",
        "            imputed_count += 1\n",
        "            print(f\"  ‚úì {col}\")\n",
        "            print(f\"    Missing: {missing_before} | Mode: {mode_value}\")\n",
        "\n",
        "if imputed_count == 0:\n",
        "    print(\"  ‚úì No missing values in ordinal features\")\n",
        "\n",
        "print(f\"\\n‚úÖ Imputed {imputed_count} ordinal features\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjcrbQCSIVDH",
        "outputId": "65fb3df8-a907-4d79-e695-524a4ce962fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üìä IMPUTING: Ordinal Features with MODE\n",
            "================================================================================\n",
            "  ‚úì No missing values in ordinal features\n",
            "\n",
            "‚úÖ Imputed 0 ordinal features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute Binary Feature\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìä IMPUTING: Binary Feature with MODE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "missing_before = df['Nuclear_Power_Status'].isnull().sum()\n",
        "if missing_before > 0:\n",
        "    mode_value = df['Nuclear_Power_Status'].mode()[0]\n",
        "    df['Nuclear_Power_Status'] = df['Nuclear_Power_Status'].fillna(mode_value)\n",
        "    print(f\"  ‚úì Nuclear_Power_Status\")\n",
        "    print(f\"    Missing: {missing_before} | Mode: {mode_value}\")\n",
        "else:\n",
        "    print(\"  ‚úì No missing values in Nuclear_Power_Status\")\n",
        "\n",
        "print(\"\\n‚úÖ Binary feature imputation completed\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1SL7VYdIet-",
        "outputId": "b9be7140-6bf2-415b-cdcf-835124d1a99a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üìä IMPUTING: Binary Feature with MODE\n",
            "================================================================================\n",
            "  ‚úì No missing values in Nuclear_Power_Status\n",
            "\n",
            "‚úÖ Binary feature imputation completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute Nominal Categorical Features\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìä IMPUTING: Nominal Categorical Features with 'Unknown'\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "categorical_cols = [\n",
        "    'Political_System_Type',\n",
        "    'Economic_Classification',\n",
        "    'Language_Diversity_Level'\n",
        "]\n",
        "\n",
        "imputed_count = 0\n",
        "for col in categorical_cols:\n",
        "    if col in df.columns:\n",
        "        missing_before = df[col].isnull().sum()\n",
        "        if missing_before > 0:\n",
        "            df[col] = df[col].fillna('Unknown')\n",
        "            imputed_count += 1\n",
        "            print(f\"  ‚úì {col}\")\n",
        "            print(f\"    Missing: {missing_before} | Filled with: 'Unknown'\")\n",
        "\n",
        "if imputed_count == 0:\n",
        "    print(\"  ‚úì No missing values in categorical features\")\n",
        "\n",
        "print(f\"\\n‚úÖ Imputed {imputed_count} nominal categorical features\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXbgwLa6Insh",
        "outputId": "b8393dc1-e920-4125-d96e-3874c9d9cf5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üìä IMPUTING: Nominal Categorical Features with 'Unknown'\n",
            "================================================================================\n",
            "  ‚úì No missing values in categorical features\n",
            "\n",
            "‚úÖ Imputed 0 nominal categorical features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute Remaining Numeric Features\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üìä IMPUTING: Remaining Numeric Features with MEDIAN\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "special_numeric_cols = [\n",
        "    'Population',\n",
        "    'GDP_per_Capita_USD',\n",
        "    'Migration_Rate',\n",
        "    'Immigration_Rate'\n",
        "]\n",
        "\n",
        "imputed_count = 0\n",
        "for col in special_numeric_cols:\n",
        "    if col in df.columns:\n",
        "        missing_before = df[col].isnull().sum()\n",
        "        if missing_before > 0:\n",
        "            median_value = df[col].median()\n",
        "            df[col] = df[col].fillna(median_value)\n",
        "            imputed_count += 1\n",
        "            print(f\"  ‚úì {col}\")\n",
        "            print(f\"    Missing: {missing_before} | Median: {median_value:.2f}\")\n",
        "\n",
        "if imputed_count == 0:\n",
        "    print(\"  ‚úì No missing values in remaining numeric features\")\n",
        "\n",
        "print(f\"\\n‚úÖ Imputed {imputed_count} remaining numeric features\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTMHQ1W-IwSb",
        "outputId": "8e40cd38-cab6-4553-a22b-06d16b518ab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üìä IMPUTING: Remaining Numeric Features with MEDIAN\n",
            "================================================================================\n",
            "  ‚úì Population\n",
            "    Missing: 6 | Median: 106059824.00\n",
            "  ‚úì GDP_per_Capita_USD\n",
            "    Missing: 5 | Median: 14976.00\n",
            "  ‚úì Migration_Rate\n",
            "    Missing: 16 | Median: 5.90\n",
            "  ‚úì Immigration_Rate\n",
            "    Missing: 14 | Median: 6.07\n",
            "\n",
            "‚úÖ Imputed 4 remaining numeric features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Post-Imputation Verification\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"POST-IMPUTATION VERIFICATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "remaining_missing = df.isnull().sum().sort_values(ascending=False)\n",
        "remaining_missing = remaining_missing[remaining_missing > 0]\n",
        "\n",
        "if len(remaining_missing) > 0:\n",
        "    print(\"‚ö†Ô∏è Remaining missing values:\")\n",
        "    print(remaining_missing)\n",
        "else:\n",
        "    print(\"‚úÖ SUCCESS: No missing values remain!\")\n",
        "    print(f\"\\n   Total data points: {df.shape[0] * df.shape[1]:,}\")\n",
        "    print(f\"   Complete data points: {df.notna().sum().sum():,}\")\n",
        "    print(f\"   Completeness: 100.00%\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maU4fNZDI4px",
        "outputId": "32f84615-3d0c-4c65-e857-c4310c973f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "POST-IMPUTATION VERIFICATION\n",
            "================================================================================\n",
            "‚úÖ SUCCESS: No missing values remain!\n",
            "\n",
            "   Total data points: 6,912\n",
            "   Complete data points: 6,912\n",
            "   Completeness: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ MODEL IMPACT:\n",
        "- ‚úÖ Prevents training failures (many algorithms can't handle NaN)\n",
        "- ‚úÖ Maintains distribution robustness (median unaffected by skewness)\n",
        "- ‚úÖ Preserves sample size for statistical power\n",
        "- ‚úÖ Strategic by feature type (median/mode/'Unknown')"
      ],
      "metadata": {
        "id": "jTQI0v_yJCkI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **STEP 4.8: LOG TRANSFORMATION**\n",
        "\n",
        "**What we cover here:** Applying log transformation to heavily right-skewed features to improve linearity and reduce skewness\n",
        "\n",
        "<br>\n",
        "\n",
        "WHY LOG TRANSFORM?\n",
        "\n",
        "Heavy right-skewed distributions cause:\n",
        "- ‚ùå Poor linear separability\n",
        "- ‚ùå Dominated by extreme values\n",
        "- ‚ùå Unstable gradient descent\n",
        "- ‚ùå Reduced feature importance interpretability\n",
        "\n",
        "LOG TRANSFORMATION:\n",
        "- ‚úÖ Compresses large values\n",
        "- ‚úÖ Expands small values\n",
        "- ‚úÖ Creates more symmetric distributions\n",
        "- ‚úÖ Improves model linearity assumptions\n",
        "\n",
        "WHY log1p (log(1+x)) INSTEAD OF log(x)?\n",
        "- ‚úÖ Handles zero values gracefully\n",
        "- ‚úÖ Preserves zeros (log1p(0) = 0)\n",
        "- ‚úÖ Prevents undefined values\n",
        "\n",
        "FEATURES TO TRANSFORM:\n",
        "- Features with severe right-skew (skewness > 2)"
      ],
      "metadata": {
        "id": "myvj54C2JSH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4.8 - Log Transformation\n",
        "\n",
        "\n",
        "# Features with heavy right-skew\n",
        "log_transform_features = [\n",
        "    'Population',\n",
        "    'GDP_per_Capita_USD',\n",
        "    'Olympic_Medals_Count',\n",
        "    'Carbon_Footprint'\n",
        "]\n",
        "\n",
        "print(f\"\\nApplying log1p transformation to {len(log_transform_features)} features...\")\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Skewness Comparison (Before ‚Üí After)\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"{'Feature':<35} {'Original Skew':>15} {'Log Skew':>15} {'Improvement':>15}\")\n",
        "print(\"-\" * 85)\n",
        "\n",
        "for col in log_transform_features:\n",
        "    if col in df.columns:\n",
        "        # Calculate original skewness\n",
        "        original_skew = df[col].skew()\n",
        "\n",
        "        # Apply log1p transformation\n",
        "        df[f'{col}_log'] = np.log1p(df[col])\n",
        "\n",
        "        # Calculate new skewness\n",
        "        log_skew = df[f'{col}_log'].skew()\n",
        "\n",
        "        # Calculate improvement\n",
        "        improvement = ((abs(original_skew) - abs(log_skew)) / abs(original_skew) * 100)\n",
        "\n",
        "        print(f\"{col:<35} {original_skew:>15.2f} {log_skew:>15.2f} {improvement:>14.1f}%\")\n",
        "\n",
        "print(\"\\n‚úÖ Log transformation completed!\")\n",
        "\n",
        "print(\"\\nNew log-transformed columns created:\")\n",
        "for col in log_transform_features:\n",
        "    if col in df.columns:\n",
        "        print(f\"  ‚úì {col}_log\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N0tpZuJI_cA",
        "outputId": "5a99ad91-821e-4708-e9d6-6db631bf78da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Applying log1p transformation to 4 features...\n",
            "\n",
            "================================================================================\n",
            "Skewness Comparison (Before ‚Üí After)\n",
            "================================================================================\n",
            "Feature                               Original Skew        Log Skew     Improvement\n",
            "-------------------------------------------------------------------------------------\n",
            "Population                                    -0.11           -2.35        -2136.7%\n",
            "GDP_per_Capita_USD                             0.21           -1.99         -843.3%\n",
            "Olympic_Medals_Count                           0.37           -1.76         -380.1%\n",
            "Carbon_Footprint                               0.26           -0.76         -187.0%\n",
            "\n",
            "‚úÖ Log transformation completed!\n",
            "\n",
            "New log-transformed columns created:\n",
            "  ‚úì Population_log\n",
            "  ‚úì GDP_per_Capita_USD_log\n",
            "  ‚úì Olympic_Medals_Count_log\n",
            "  ‚úì Carbon_Footprint_log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ MODEL IMPACT:\n",
        "- ‚úÖ Improves linear regression fit by meeting normality assumptions\n",
        "- ‚úÖ Stabilizes gradient descent with smoother loss landscapes\n",
        "- ‚úÖ Enhances feature importance learning in tree-based models\n",
        "- ‚úÖ Reduces influence of outliers while preserving information\n",
        "- ‚úÖ Better decision boundaries in classification tasks"
      ],
      "metadata": {
        "id": "e8IubD6RJmBF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **STEP 4.9: ONE-HOT ENCODING**\n",
        "\n",
        "**What we cover here:** Encoding nominal categorical variables (no natural order) using one-hot encoding with drop_first to avoid multicollinearity\n"
      ],
      "metadata": {
        "id": "9K79lyPsJ-z_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4.9 - One-Hot Encoding\n",
        "\n",
        "# First, drop original ordinal text columns (already encoded)\n",
        "print(\"\\nüóëÔ∏è Dropping original ordinal text columns (already encoded)...\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "original_ordinal_cols = [\n",
        "    'Regulation_Strictness',\n",
        "    'Happiness_Index',\n",
        "    'Space_Tech_Level'\n",
        "]\n",
        "\n",
        "columns_to_drop = [col for col in original_ordinal_cols if col in df.columns]\n",
        "if len(columns_to_drop) > 0:\n",
        "    df = df.drop(columns=columns_to_drop)\n",
        "    print(f\"  ‚úì Dropped: {columns_to_drop}\")\n",
        "else:\n",
        "    print(\"  ‚úì Columns already removed or not present\")\n",
        "\n",
        "# Identify nominal categorical columns for one-hot encoding\n",
        "print(\"\\nüéØ Applying One-Hot Encoding to nominal categorical features...\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "nominal_cols = [\n",
        "    'Political_System_Type',\n",
        "    'Economic_Classification',\n",
        "    'Language_Diversity_Level'\n",
        "]\n",
        "\n",
        "# Show unique values before encoding\n",
        "print(\"\\nUnique values in each nominal feature:\")\n",
        "for col in nominal_cols:\n",
        "    if col in df.columns:\n",
        "        unique_vals = df[col].unique()\n",
        "        print(f\"\\n  ‚Ä¢ {col} ({len(unique_vals)} categories)\")\n",
        "        print(f\"    Categories: {sorted(unique_vals)}\")\n",
        "\n",
        "# Apply one-hot encoding with drop_first=True\n",
        "initial_shape = df.shape\n",
        "df = pd.get_dummies(\n",
        "    df,\n",
        "    columns=nominal_cols,\n",
        "    drop_first=True  # Avoid dummy variable trap\n",
        ")\n",
        "final_shape = df.shape\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ONE-HOT ENCODING RESULTS\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Shape before encoding: {initial_shape}\")\n",
        "print(f\"Shape after encoding:  {final_shape}\")\n",
        "print(f\"New columns created:   {final_shape[1] - initial_shape[1]}\")\n",
        "\n",
        "# Show new one-hot encoded columns\n",
        "new_cols = [col for col in df.columns if any(nom in col for nom in nominal_cols)]\n",
        "print(f\"\\nNew one-hot encoded columns ({len(new_cols)}):\")\n",
        "for col in sorted(new_cols):\n",
        "    print(f\"  ‚úì {col}\")\n",
        "\n",
        "print(\"\\n‚úÖ One-hot encoding completed successfully!\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtV6BGofJjBb",
        "outputId": "65c89938-e39c-4ecf-f767-df8241c83a3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üóëÔ∏è Dropping original ordinal text columns (already encoded)...\n",
            "--------------------------------------------------------------------------------\n",
            "  ‚úì Dropped: ['Regulation_Strictness', 'Happiness_Index', 'Space_Tech_Level']\n",
            "\n",
            "üéØ Applying One-Hot Encoding to nominal categorical features...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Unique values in each nominal feature:\n",
            "\n",
            "  ‚Ä¢ Political_System_Type (6 categories)\n",
            "    Categories: ['Autocracy', 'Democracy', 'Federal Monarchy', 'Hybrid', 'Military Junta', 'Transitional']\n",
            "\n",
            "  ‚Ä¢ Economic_Classification (3 categories)\n",
            "    Categories: ['Developed', 'Developing', 'Underdeveloped']\n",
            "\n",
            "  ‚Ä¢ Language_Diversity_Level (8 categories)\n",
            "    Categories: ['High', 'High;Low', 'Low', 'Low;High', 'Low;Medium', 'Medium', 'Medium;High', 'Medium;Low']\n",
            "\n",
            "================================================================================\n",
            "ONE-HOT ENCODING RESULTS\n",
            "================================================================================\n",
            "Shape before encoding: (192, 37)\n",
            "Shape after encoding:  (192, 48)\n",
            "New columns created:   11\n",
            "\n",
            "New one-hot encoded columns (14):\n",
            "  ‚úì Economic_Classification_Developing\n",
            "  ‚úì Economic_Classification_Underdeveloped\n",
            "  ‚úì Language_Diversity_Level_High;Low\n",
            "  ‚úì Language_Diversity_Level_Low\n",
            "  ‚úì Language_Diversity_Level_Low;High\n",
            "  ‚úì Language_Diversity_Level_Low;Medium\n",
            "  ‚úì Language_Diversity_Level_Medium\n",
            "  ‚úì Language_Diversity_Level_Medium;High\n",
            "  ‚úì Language_Diversity_Level_Medium;Low\n",
            "  ‚úì Political_System_Type_Democracy\n",
            "  ‚úì Political_System_Type_Federal Monarchy\n",
            "  ‚úì Political_System_Type_Hybrid\n",
            "  ‚úì Political_System_Type_Military Junta\n",
            "  ‚úì Political_System_Type_Transitional\n",
            "\n",
            "‚úÖ One-hot encoding completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ MODEL IMPACT:\n",
        "- ‚úÖ No false ordinal assumptions for truly nominal data\n",
        "- ‚úÖ Prevents multicollinearity via drop_first\n",
        "- ‚úÖ Compatible with all algorithms (linear, trees, neural nets)\n",
        "- ‚úÖ Maintains interpretability (each column = specific category)"
      ],
      "metadata": {
        "id": "OVGURpE1KIvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **STEP 4.10: FEATURE CLEANUP**\n",
        "\n",
        "**What we cover here:** Removing non-predictive identifier columns that could cause overfitting\n",
        "\n",
        "<br>\n",
        "\n",
        "WHY REMOVE NON-PREDICTIVE FEATURES?\n",
        "\n",
        "Features like Country_Name are:\n",
        "- ‚ùå Identifiers, not predictors\n",
        "- ‚ùå High cardinality (each value unique)\n",
        "- ‚ùå Risk of overfitting to specific countries\n",
        "- ‚ùå No generalization value for unseen data\n",
        "\n",
        "<br>\n",
        "\n",
        "REMOVING THESE FEATURES:\n",
        "- ‚úÖ Prevents memorization of training data\n",
        "- ‚úÖ Improves generalization to new/unseen countries\n",
        "- ‚úÖ Reduces model complexity and training time\n",
        "- ‚úÖ Focuses learning on true predictive features"
      ],
      "metadata": {
        "id": "o7U1oWAUKWrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4.10 - Feature Cleanup\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"STEP 6.10: FEATURE CLEANUP\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\"\"\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "print(\"\\nüóëÔ∏è Removing non-predictive identifier columns...\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Remove country name (identifier, not predictor)\n",
        "if 'Country_Name' in df.columns:\n",
        "    df = df.drop(columns=['Country_Name'])\n",
        "    print(\"  ‚úì Removed: Country_Name\")\n",
        "    print(\"    Reason: Identifier with no predictive value\")\n",
        "else:\n",
        "    print(\"  ‚ö†Ô∏è Country_Name already removed or not present\")\n",
        "\n",
        "print(\"\\n‚úÖ Feature cleanup completed!\")\n",
        "print(f\"\\nFinal feature count: {df.shape[1]} columns\")\n",
        "print(f\"Final sample count: {df.shape[0]} rows\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OX344YIKG7G",
        "outputId": "30648b1f-4000-4c5b-a3fe-7e45a39fcfde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "STEP 6.10: FEATURE CLEANUP\n",
            "================================================================================\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "üóëÔ∏è Removing non-predictive identifier columns...\n",
            "--------------------------------------------------------------------------------\n",
            "  ‚úì Removed: Country_Name\n",
            "    Reason: Identifier with no predictive value\n",
            "\n",
            "‚úÖ Feature cleanup completed!\n",
            "\n",
            "Final feature count: 47 columns\n",
            "Final sample count: 192 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ MODEL IMPACT:\n",
        "- ‚úÖ Prevents memorization of specific country names\n",
        "- ‚úÖ Improves generalization to new/unseen countries\n",
        "- ‚úÖ Reduces model complexity and training time\n",
        "- ‚úÖ Focuses learning on true predictive features"
      ],
      "metadata": {
        "id": "U4r9gBw9Kn9S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SECTION 5: FINAL VALIDATION & VERIFICATION**\n",
        "\n",
        "**What we cover here:** Comprehensive validation checks to ensure preprocessing was successful and data is model-ready\n"
      ],
      "metadata": {
        "id": "g6AfHlDzK3HO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Validation - Check 1 (Missing Values)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"FINAL PREPROCESSING VALIDATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n‚úÖ CHECK 1: Missing Values\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "total_missing = df.isnull().sum().sum()\n",
        "if total_missing == 0:\n",
        "    print(f\"  ‚úì PASS: No missing values in dataset\")\n",
        "    print(f\"\\n    Total cells: {df.shape[0] * df.shape[1]:,}\")\n",
        "    print(f\"    Complete cells: {df.notna().sum().sum():,}\")\n",
        "    print(f\"    Completeness: 100.00%\")\n",
        "else:\n",
        "    print(f\"  ‚úó FAIL: {total_missing} missing values found\")\n",
        "    print(\"\\n  Missing by column:\")\n",
        "    print(df.isnull().sum()[df.isnull().sum() > 0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcuyQRGTKlg_",
        "outputId": "3521740f-a387-40a0-fec0-aa1d5419aeb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "FINAL PREPROCESSING VALIDATION\n",
            "================================================================================\n",
            "\n",
            "‚úÖ CHECK 1: Missing Values\n",
            "--------------------------------------------------------------------------------\n",
            "  ‚úì PASS: No missing values in dataset\n",
            "\n",
            "    Total cells: 9,024\n",
            "    Complete cells: 9,024\n",
            "    Completeness: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Validation - Check 2 (Data Types)\n",
        "\n",
        "print(\"\\n‚úÖ CHECK 2: Data Types\")\n",
        "print(\"-\" * 80)\n",
        "print(\"\\nData type distribution:\")\n",
        "print(df.dtypes.value_counts())\n",
        "\n",
        "# Verify no object columns except intentional ones\n",
        "object_cols = df.select_dtypes(include='object').columns\n",
        "if len(object_cols) == 0:\n",
        "    print(\"\\n  ‚úì PASS: All features are numeric (model-ready)\")\n",
        "else:\n",
        "    print(f\"\\n  ‚ö†Ô∏è WARNING: {len(object_cols)} object columns remain:\")\n",
        "    for col in object_cols:\n",
        "        print(f\"    ‚Ä¢ {col}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6-sXC2aK6mW",
        "outputId": "cbdbec97-9278-40fe-f16a-1698268d1204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ CHECK 2: Data Types\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Data type distribution:\n",
            "float64    22\n",
            "bool       14\n",
            "int64      11\n",
            "Name: count, dtype: int64\n",
            "\n",
            "  ‚úì PASS: All features are numeric (model-ready)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Validation - Check 3 (Feature Engineering)\n",
        "\n",
        "print(\"\\n‚úÖ CHECK 3: Feature Engineering Results\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"  Final Features: {df.shape[1]}\")\n",
        "print(f\"  Final Samples: {df.shape[0]}\")\n",
        "print(f\"  Total Data Points: {df.shape[0] * df.shape[1]:,}\")\n",
        "\n",
        "# Count different types of features\n",
        "log_features = [col for col in df.columns if '_log' in col]\n",
        "ordinal_features = [col for col in df.columns if '_Ordinal' in col]\n",
        "onehot_features = [col for col in df.columns if any(nom in col for nom in\n",
        "                   ['Political_System_Type', 'Economic_Classification', 'Language_Diversity_Level'])]\n",
        "\n",
        "print(f\"\\nFeature breakdown:\")\n",
        "print(f\"  Log-transformed: {len(log_features)}\")\n",
        "print(f\"  Ordinal encoded: {len(ordinal_features)}\")\n",
        "print(f\"  One-hot encoded: {len(onehot_features)}\")\n",
        "print(f\"  Other numeric: {df.shape[1] - len(log_features) - len(ordinal_features) - len(onehot_features)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzkEp9MPK_oz",
        "outputId": "aa46b730-dfd4-4ea9-d5f6-6ddbb7b0bd38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ CHECK 3: Feature Engineering Results\n",
            "--------------------------------------------------------------------------------\n",
            "  Final Features: 47\n",
            "  Final Samples: 192\n",
            "  Total Data Points: 9,024\n",
            "\n",
            "Feature breakdown:\n",
            "  Log-transformed: 4\n",
            "  Ordinal encoded: 3\n",
            "  One-hot encoded: 14\n",
            "  Other numeric: 26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Final Validation - Check 4 (Target Variables)\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n‚úÖ CHECK 4: Target Variables\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "target_checks = [\n",
        "    ('HDI_Index', 'Regression Target'),\n",
        "    ('Happiness_Index_Ordinal', 'Classification Target')\n",
        "]\n",
        "\n",
        "all_targets_present = True\n",
        "\n",
        "for target, description in target_checks:\n",
        "    if target in df.columns:\n",
        "        print(f\"\\n  ‚úì {description}: {target}\")\n",
        "        print(f\"    Type: {df[target].dtype}\")\n",
        "        print(f\"    Range: [{df[target].min():.4f}, {df[target].max():.4f}]\")\n",
        "\n",
        "        # Additional checks for classification target\n",
        "        if target == 'Happiness_Index_Ordinal':\n",
        "            print(f\"    Classes: {sorted(df[target].dropna().unique())}\")\n",
        "            print(\"    Class distribution:\")\n",
        "            print(f\"    {df[target].value_counts().sort_index().to_dict()}\")\n",
        "    else:\n",
        "        print(f\"\\n  ‚úó MISSING: {description} ({target})\")\n",
        "        all_targets_present = False\n",
        "\n",
        "if all_targets_present:\n",
        "    print(\"\\n  ‚úì PASS: All target variables present and valid\")\n",
        "else:\n",
        "    print(\"\\n  ‚úó FAIL: One or more target variables are missing\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2iSN7evLEaW",
        "outputId": "0331617c-ecdd-4e31-cf28-c3b6d1795e26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ CHECK 4: Target Variables\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  ‚úì Regression Target: HDI_Index\n",
            "    Type: float64\n",
            "    Range: [0.1901, 0.8504]\n",
            "\n",
            "  ‚úì Classification Target: Happiness_Index_Ordinal\n",
            "    Type: int64\n",
            "    Range: [1.0000, 4.0000]\n",
            "    Classes: [np.int64(1), np.int64(3), np.int64(4)]\n",
            "    Class distribution:\n",
            "    {1: 59, 3: 105, 4: 28}\n",
            "\n",
            "  ‚úì PASS: All target variables present and valid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Validation - Check 5 (Statistical Summary)\n",
        "\n",
        "print(\"\\n‚úÖ CHECK 5: Statistical Summary (Sample of Key Features)\")\n",
        "print(\"-\" * 80)\n",
        "print(df.describe().T.head(15))\n",
        "\n",
        "# Cell 45: Final Validation Summary\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"PREPROCESSING PIPELINE: ‚úÖ VALIDATION COMPLETE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "validation_results = {\n",
        "    'Missing Values': total_missing == 0,\n",
        "    'All Numeric': len(object_cols) == 0,\n",
        "    'Targets Present': all_targets_present,\n",
        "    'Feature Engineering': df.shape[1] > 20  # Assuming we have reasonable features\n",
        "}\n",
        "\n",
        "print(\"\\nValidation Summary:\")\n",
        "for check, passed in validation_results.items():\n",
        "    status = \"‚úÖ PASS\" if passed else \"‚ùå FAIL\"\n",
        "    print(f\"  {status}: {check}\")\n",
        "\n",
        "if all(validation_results.values()):\n",
        "    print(\"\\nüéâ SUCCESS: Dataset is MODEL-READY for training!\")\n",
        "    print(\"\\nüìä Final Dataset Statistics:\")\n",
        "    print(f\"   ‚Ä¢ Rows: {df.shape[0]:,}\")\n",
        "    print(f\"   ‚Ä¢ Features: {df.shape[1]:,}\")\n",
        "    print(f\"   ‚Ä¢ Completeness: 100%\")\n",
        "    print(f\"   ‚Ä¢ All numeric: Yes\")\n",
        "    print(f\"   ‚Ä¢ Targets present: Yes\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è WARNING: Some validation checks failed - review above\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smZzvy1pLWVs",
        "outputId": "2ae8dd34-3ea9-4981-971a-aebab834ae1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ CHECK 5: Statistical Summary (Sample of Key Features)\n",
            "--------------------------------------------------------------------------------\n",
            "                                    count          mean           std  \\\n",
            "Population                          192.0  1.007353e+08  5.439117e+07   \n",
            "GDP_per_Capita_USD                  192.0  1.527482e+04  8.224863e+03   \n",
            "Literacy_Rate_pct                   192.0  6.045927e+01  1.733445e+01   \n",
            "Internet_Access_pct                 192.0  4.207145e+01  2.006253e+01   \n",
            "Gender_Equality_Index               192.0  5.060758e+01  1.740699e+01   \n",
            "Higher_Education_Rate               192.0  2.372427e+01  1.818674e+01   \n",
            "Govt_Education_Expenditure_pct_GDP  192.0  4.355602e+00  4.211344e+00   \n",
            "Life_Expectancy_years               192.0  6.535764e+01  5.490702e+00   \n",
            "Unemployment_Rate_pct               192.0  4.251422e+00  9.629637e+00   \n",
            "Days_engaged_in_warfare_per_year    192.0  1.973958e+01  9.224080e+00   \n",
            "Carbon_Footprint                    192.0  7.184579e+00  3.307399e+00   \n",
            "Medical_Doctors_per_1000            192.0  1.727284e+00  7.792558e-01   \n",
            "R_and_D_Expenditure_pct_GDP         192.0  3.570428e+00  7.757014e+00   \n",
            "Number_of_Patents                   192.0  1.228533e+04  7.585079e+03   \n",
            "Number_of_Startups                  192.0  8.956724e+03  6.850022e+03   \n",
            "\n",
            "                                         min           25%           50%  \\\n",
            "Population                          241004.0  5.487632e+07  1.060598e+08   \n",
            "GDP_per_Capita_USD                     500.0  9.910750e+03  1.497600e+04   \n",
            "Literacy_Rate_pct                        0.0  4.949659e+01  5.859302e+01   \n",
            "Internet_Access_pct                      0.0  2.915170e+01  3.932034e+01   \n",
            "Gender_Equality_Index                    0.0  3.949659e+01  4.859302e+01   \n",
            "Higher_Education_Rate                    0.0  9.993764e+00  1.990232e+01   \n",
            "Govt_Education_Expenditure_pct_GDP       0.0  3.702850e-01  3.406166e+00   \n",
            "Life_Expectancy_years                   50.0  6.181978e+01  6.546645e+01   \n",
            "Unemployment_Rate_pct                    0.0  1.549884e-01  2.315196e-01   \n",
            "Days_engaged_in_warfare_per_year         0.0  1.400000e+01  1.900000e+01   \n",
            "Carbon_Footprint                         1.0  4.641849e+00  7.321218e+00   \n",
            "Medical_Doctors_per_1000                 0.1  1.276872e+00  1.667248e+00   \n",
            "R_and_D_Expenditure_pct_GDP              0.0  0.000000e+00  2.171217e+00   \n",
            "Number_of_Patents                        0.0  6.392750e+03  1.263850e+04   \n",
            "Number_of_Startups                       0.0  3.250500e+03  8.884000e+03   \n",
            "\n",
            "                                             75%           max  \n",
            "Population                          1.436181e+08  1.951432e+08  \n",
            "GDP_per_Capita_USD                  2.042500e+04  3.688100e+04  \n",
            "Literacy_Rate_pct                   7.207891e+01  1.000000e+02  \n",
            "Internet_Access_pct                 5.541531e+01  1.000000e+02  \n",
            "Gender_Equality_Index               6.207891e+01  1.000000e+02  \n",
            "Higher_Education_Rate               3.541531e+01  1.000000e+02  \n",
            "Govt_Education_Expenditure_pct_GDP  6.962660e+00  1.811983e+01  \n",
            "Life_Expectancy_years               6.871033e+01  8.097924e+01  \n",
            "Unemployment_Rate_pct               3.734710e-01  4.108278e+01  \n",
            "Days_engaged_in_warfare_per_year    2.500000e+01  5.000000e+01  \n",
            "Carbon_Footprint                    9.635254e+00  1.755618e+01  \n",
            "Medical_Doctors_per_1000            2.126657e+00  3.842458e+00  \n",
            "R_and_D_Expenditure_pct_GDP         5.141006e+00  9.819870e+01  \n",
            "Number_of_Patents                   1.662600e+04  3.216962e+04  \n",
            "Number_of_Startups                  1.280200e+04  2.712925e+04  \n",
            "\n",
            "================================================================================\n",
            "PREPROCESSING PIPELINE: ‚úÖ VALIDATION COMPLETE\n",
            "================================================================================\n",
            "\n",
            "Validation Summary:\n",
            "  ‚úÖ PASS: Missing Values\n",
            "  ‚úÖ PASS: All Numeric\n",
            "  ‚úÖ PASS: Targets Present\n",
            "  ‚úÖ PASS: Feature Engineering\n",
            "\n",
            "üéâ SUCCESS: Dataset is MODEL-READY for training!\n",
            "\n",
            "üìä Final Dataset Statistics:\n",
            "   ‚Ä¢ Rows: 192\n",
            "   ‚Ä¢ Features: 47\n",
            "   ‚Ä¢ Completeness: 100%\n",
            "   ‚Ä¢ All numeric: Yes\n",
            "   ‚Ä¢ Targets present: Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SECTION 6: EXPORT PREPROCESSED DATA**\n"
      ],
      "metadata": {
        "id": "oKf99RrpLtKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export Data\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"EXPORTING PREPROCESSED DATA\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Export to CSV\n",
        "output_path_csv = \"soil_hackathon_cleaned_model_ready.csv\"\n",
        "df.to_csv(output_path_csv, index=False)\n",
        "print(f\"\\n‚úÖ CSV exported: {output_path_csv}\")\n",
        "print(f\"   Size: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
        "print(f\"   File saved to current directory\")\n",
        "\n",
        "# Export to Excel (more readable for review)\n",
        "output_path_xlsx = \"soil_hackathon_cleaned_model_ready.xlsx\"\n",
        "df.to_excel(output_path_xlsx, index=False)\n",
        "print(f\"\\n‚úÖ Excel exported: {output_path_xlsx}\")\n",
        "print(f\"   Size: {df.shape[0]} rows √ó {df.shape[1]} columns\")\n",
        "print(f\"   File saved to current directory\")\n",
        "\n",
        "# Download files (if running in Google Colab)\n",
        "print(\"\\nüì• Attempting to download files (Colab only)...\")\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(output_path_xlsx)\n",
        "    print(\"‚úÖ Download initiated for Excel file\")\n",
        "    print(\"   (CSV also available in Colab file system)\")\n",
        "except:\n",
        "    print(\"‚ÑπÔ∏è  Not in Colab environment - files saved locally\")\n",
        "    print(\"   Access files from your local directory\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"EXPORT COMPLETE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "THldF1BZLl-A",
        "outputId": "9e2776ce-c428-4c93-c9e9-7cf2aa5ed515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "EXPORTING PREPROCESSED DATA\n",
            "================================================================================\n",
            "\n",
            "‚úÖ CSV exported: soil_hackathon_cleaned_model_ready.csv\n",
            "   Size: 192 rows √ó 47 columns\n",
            "   File saved to current directory\n",
            "\n",
            "‚úÖ Excel exported: soil_hackathon_cleaned_model_ready.xlsx\n",
            "   Size: 192 rows √ó 47 columns\n",
            "   File saved to current directory\n",
            "\n",
            "üì• Attempting to download files (Colab only)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d132cef4-7032-46e0-858d-106aff258a54\", \"soil_hackathon_cleaned_model_ready.xlsx\", 67774)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Download initiated for Excel file\n",
            "   (CSV also available in Colab file system)\n",
            "\n",
            "================================================================================\n",
            "EXPORT COMPLETE\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SECTION 7: WHY THIS PREPROCESSING REDUCES MODEL ERROR**\n",
        "\n",
        "**What we cover here:** Direct linkage between each preprocessing step and model performance improvement\n"
      ],
      "metadata": {
        "id": "-bqGvYAXL3OO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Error Reduction Analysis\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"WHY THIS PREPROCESSING REDUCES MODEL ERROR\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\"\"\n",
        "ERROR REDUCTION MECHANISMS:\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "Preprocessing Step          Error Reduction Mechanism          Impact\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "Type Correction             Eliminates runtime failures        Enables training\n",
        "\n",
        "Ordinal Encoding            Preserves hierarchy for            Improves R¬≤\n",
        "                            monotonic learning\n",
        "\n",
        "Binary Encoding             Simple, unambiguous                No information loss\n",
        "                            representation\n",
        "\n",
        "Scale Standardization       Prevents feature dominance         Faster convergence\n",
        "\n",
        "Outlier Capping             Reduces overfitting to             Lower CV variance\n",
        "                            extremes\n",
        "\n",
        "Bound Enforcement           Aligns with domain                 Trustworthy\n",
        "                            constraints                        predictions\n",
        "\n",
        "Missing Imputation          Maintains sample size &            Stable estimates\n",
        "                            distribution\n",
        "\n",
        "Log Transformation          Improves linearity &               Better gradient\n",
        "                            symmetry                           flow\n",
        "\n",
        "One-Hot Encoding            No false ordinal                   Correct feature\n",
        "                            assumptions                        learning\n",
        "\n",
        "Feature Cleanup             Focuses on predictive              Better\n",
        "                            features                           generalization\n",
        "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBNY6AfLLyWN",
        "outputId": "30dc80e9-964a-4f14-bdb7-287fa4139ad2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "WHY THIS PREPROCESSING REDUCES MODEL ERROR\n",
            "================================================================================\n",
            "\n",
            "ERROR REDUCTION MECHANISMS:\n",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
            "Preprocessing Step          Error Reduction Mechanism          Impact\n",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
            "Type Correction             Eliminates runtime failures        Enables training\n",
            "\n",
            "Ordinal Encoding            Preserves hierarchy for            Improves R¬≤\n",
            "                            monotonic learning                 \n",
            "\n",
            "Binary Encoding             Simple, unambiguous                No information loss\n",
            "                            representation                     \n",
            "\n",
            "Scale Standardization       Prevents feature dominance         Faster convergence\n",
            "\n",
            "Outlier Capping             Reduces overfitting to             Lower CV variance\n",
            "                            extremes                           \n",
            "\n",
            "Bound Enforcement           Aligns with domain                 Trustworthy\n",
            "                            constraints                        predictions\n",
            "\n",
            "Missing Imputation          Maintains sample size &            Stable estimates\n",
            "                            distribution                       \n",
            "\n",
            "Log Transformation          Improves linearity &               Better gradient\n",
            "                            symmetry                           flow\n",
            "\n",
            "One-Hot Encoding            No false ordinal                   Correct feature\n",
            "                            assumptions                        learning\n",
            "\n",
            "Feature Cleanup             Focuses on predictive              Better\n",
            "                            features                           generalization\n",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üéØ EXPECTED MODEL IMPROVEMENTS:\n",
        "\n",
        "1. REGRESSION (HDI Prediction):\n",
        "  - ‚úÖ Lower RMSE via outlier control and scale normalization\n",
        "  - ‚úÖ Higher R¬≤ through preserved ordinal relationships\n",
        "  - ‚úÖ Better linearity from log transformations\n",
        "  - ‚úÖ Stable coefficients from multicollinearity reduction\n",
        "  - ‚úÖ Improved feature importance interpretability\n",
        "\n",
        "2. CLASSIFICATION (Happiness Prediction):\n",
        "  - ‚úÖ Higher Accuracy from properly encoded ordinal targets\n",
        "  - ‚úÖ Better class boundaries via scale harmonization\n",
        "  - ‚úÖ Improved F1-Score through balanced feature importance\n",
        "  - ‚úÖ Consistent CV scores from robust imputation\n",
        "  - ‚úÖ Reduced overfitting through strategic transformations"
      ],
      "metadata": {
        "id": "PBLOBnjeMZ3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DATASET STATUS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"\"\"\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ FINAL DATASET STATISTICS                                ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ Rows (Countries):        {df.shape[0]:>6,}                         ‚îÇ\n",
        "‚îÇ Features:                {df.shape[1]:>6,}                         ‚îÇ\n",
        "‚îÇ Missing Values:          {df.isnull().sum().sum():>6,} (100% complete)         ‚îÇ\n",
        "‚îÇ Data Types:              All numeric (model-ready)      ‚îÇ\n",
        "‚îÇ Outliers:                Controlled via IQR capping     ‚îÇ\n",
        "‚îÇ Skewness:                Reduced via log transform      ‚îÇ\n",
        "‚îÇ Scale:                   Harmonized                     ‚îÇ\n",
        "‚îÇ Encoding:                Complete (ordinal + one-hot)   ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3L0YtRnM3VS",
        "outputId": "49871af6-6766-4cbd-8ce1-bd125e43fea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "DATASET STATUS\n",
            "================================================================================\n",
            "\n",
            "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
            "‚îÇ FINAL DATASET STATISTICS                                ‚îÇ\n",
            "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
            "‚îÇ Rows (Countries):           192                         ‚îÇ\n",
            "‚îÇ Features:                    47                         ‚îÇ\n",
            "‚îÇ Missing Values:               0 (100% complete)         ‚îÇ\n",
            "‚îÇ Data Types:              All numeric (model-ready)      ‚îÇ\n",
            "‚îÇ Outliers:                Controlled via IQR capping     ‚îÇ\n",
            "‚îÇ Skewness:                Reduced via log transform      ‚îÇ\n",
            "‚îÇ Scale:                   Harmonized                     ‚îÇ\n",
            "‚îÇ Encoding:                Complete (ordinal + one-hot)   ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mAKQ3ycdLxZ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}